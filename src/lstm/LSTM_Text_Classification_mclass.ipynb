{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LSTM_Text_Classification_mclass_02.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"m0iA62ypNeSH"},"source":["# Parameters"]},{"cell_type":"code","metadata":{"id":"q5I4SZfwOVS0","executionInfo":{"status":"ok","timestamp":1602834745196,"user_tz":-120,"elapsed":868,"user":{"displayName":"Burcu Sayin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGwX32JPCvOoC3v5AsaJG8UrIAZoJ7VXcix4Coyg=s64","userId":"04171978679196166536"}}},"source":["source_folder = '/content/drive/My Drive/Colab Notebooks/Datasets/binary/'\n","res_path = '/content/drive/My Drive/Colab Notebooks/Datasets/res/'"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"BYZUp3qpXkvx","executionInfo":{"status":"ok","timestamp":1602834750122,"user_tz":-120,"elapsed":5765,"user":{"displayName":"Burcu Sayin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGwX32JPCvOoC3v5AsaJG8UrIAZoJ7VXcix4Coyg=s64","userId":"04171978679196166536"}},"outputId":"89a0e16b-d9bf-429c-ce24-b2bb399324a4","colab":{"base_uri":"https://localhost:8080/","height":347}},"source":["!pip install sklearn\n","!pip install netcal"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.22.2.post1)\n","Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.18.5)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.4.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (0.16.0)\n","Requirement already satisfied: netcal in /usr/local/lib/python3.6/dist-packages (1.1.2)\n","Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from netcal) (1.18.5)\n","Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from netcal) (0.22.2.post1)\n","Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from netcal) (1.6.0+cu101)\n","Requirement already satisfied: scipy>=1.3 in /usr/local/lib/python3.6/dist-packages (from netcal) (1.4.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from netcal) (4.41.1)\n","Requirement already satisfied: matplotlib>=3.1 in /usr/local/lib/python3.6/dist-packages (from netcal) (3.2.2)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->netcal) (0.16.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.1->netcal) (0.16.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.1->netcal) (2.4.7)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.1->netcal) (1.2.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.1->netcal) (2.8.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.1->netcal) (0.10.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib>=3.1->netcal) (1.15.0)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mqB-iSUGNnkJ"},"source":["# Libraries"]},{"cell_type":"code","metadata":{"id":"tgWpYREtQns9","executionInfo":{"status":"ok","timestamp":1602834750125,"user_tz":-120,"elapsed":5760,"user":{"displayName":"Burcu Sayin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGwX32JPCvOoC3v5AsaJG8UrIAZoJ7VXcix4Coyg=s64","userId":"04171978679196166536"}}},"source":["# Libraries\n","import os\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import torch\n","import numpy as np\n","\n","# Preliminaries\n","\n","from torchtext.data import Field, TabularDataset, BucketIterator\n","\n","# Models\n","\n","import torch.nn as nn\n","from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n","\n","# Training\n","\n","import torch.optim as optim\n","\n","# Evaluation\n","\n","from sklearn.metrics import precision_recall_fscore_support\n","from netcal.metrics import ECE"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"MthpYZhpkyx6","executionInfo":{"status":"ok","timestamp":1602834750125,"user_tz":-120,"elapsed":5715,"user":{"displayName":"Burcu Sayin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGwX32JPCvOoC3v5AsaJG8UrIAZoJ7VXcix4Coyg=s64","userId":"04171978679196166536"}},"outputId":"92780e37-0a06-4f7a-f753-b25b899e1088","colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","print(device)\n","\n","## Mount Drive into Colab\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":20,"outputs":[{"output_type":"stream","text":["cuda:0\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"u6dyP4Y7Nq0b"},"source":["# Preliminaries"]},{"cell_type":"code","metadata":{"id":"N1T5QcSENZ0z","executionInfo":{"status":"ok","timestamp":1602834750418,"user_tz":-120,"elapsed":5977,"user":{"displayName":"Burcu Sayin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGwX32JPCvOoC3v5AsaJG8UrIAZoJ7VXcix4Coyg=s64","userId":"04171978679196166536"}},"outputId":"5776be75-b4f1-45d7-e0d0-41d170f18ab9","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# data \n","training = '8_train_drug_relation_mclass.csv'\n","val = '8_val_drug_relation_mclass.csv'\n","testing = '8_test_drug_relation_mclass.csv'\n","logfile_name = \"8-lsmooth-lstm-drug_relation-lr10-3-1&3&3cw-a02_em500_dr02_maxEp500.csv\"\n","\n","num_classes = 3\n","class_weight = torch.Tensor([1, 3, 3])\n","learning_rate = 1e-03\n","max_epochs = 500\n","batch_size = 32\n","alpha = 0.2  # smoothing parameters for true label\n","embedding_size = 500\n","dropout_rate =0.2\n","\n","\n","# Fields\n","\n","label_field = Field(sequential=False, use_vocab=False, batch_first=True, dtype=torch.float)\n","text_field = Field(tokenize='spacy', lower=True, include_lengths=True, batch_first=True)\n","fields = [('text', text_field), ('crowd_label', label_field), ('conf0', label_field), ('conf1', label_field), ('conf2', label_field)]\n","\n","# TabularDataset\n","\n","train, valid, test = TabularDataset.splits(path=source_folder, train=training, validation=val, test=testing,\n","                                           format='CSV', fields=fields, skip_header=True)\n","\n","# Iterators\n","\n","train_iter = BucketIterator(train, batch_size=batch_size, sort_key=lambda x: len(x.text),\n","                            device=device, sort=True, sort_within_batch=True)\n","valid_iter = BucketIterator(valid, batch_size=1, sort_key=lambda x: len(x.text),\n","                            device=device, sort=True, sort_within_batch=True)\n","test_iter = BucketIterator(test, batch_size=1, sort_key=lambda x: len(x.text),\n","                            device=device, sort=True, sort_within_batch=True)\n","\n","# Vocabulary\n","print(train)\n","text_field.build_vocab(train, min_freq=3)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["<torchtext.data.dataset.TabularDataset object at 0x7faa08cd0dd8>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Gocz9HMqNvtb"},"source":["# Models"]},{"cell_type":"code","metadata":{"id":"soc-PApFBmyC","executionInfo":{"status":"ok","timestamp":1602834750419,"user_tz":-120,"elapsed":5971,"user":{"displayName":"Burcu Sayin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGwX32JPCvOoC3v5AsaJG8UrIAZoJ7VXcix4Coyg=s64","userId":"04171978679196166536"}}},"source":["#bidirectional LSTM model\n","class LSTM(nn.Module):\n","\n","    def __init__(self, dimension=128):\n","        super(LSTM, self).__init__()\n","\n","        self.embedding = nn.Embedding(len(text_field.vocab), embedding_size)\n","        self.dimension = dimension\n","        self.lstm = nn.LSTM(input_size=embedding_size,\n","                            hidden_size=dimension,\n","                            num_layers=1,\n","                            batch_first=True,\n","                            bidirectional=True)\n","        self.drop = nn.Dropout(p=dropout_rate)\n","\n","        self.fc = nn.Linear(2*dimension, num_classes)\n","\n","    def forward(self, text, text_len):\n","\n","        text_emb = self.embedding(text)\n","\n","        packed_input = pack_padded_sequence(text_emb, text_len, batch_first=True, enforce_sorted=False)\n","        packed_output, _ = self.lstm(packed_input)\n","        output, _ = pad_packed_sequence(packed_output, batch_first=True)\n","\n","        out_forward = output[range(len(output)), text_len - 1, :self.dimension]\n","        out_reverse = output[:, 0, self.dimension:]\n","        out_reduced = torch.cat((out_forward, out_reverse), 1)\n","        text_fea = self.drop(out_reduced)\n","\n","        text_fea = self.fc(text_fea)\n","        #text_fea = torch.squeeze(text_fea, 1)\n","        #text_out = torch.sigmoid(text_fea)\n","\n","        return text_fea\n","\n","  #  def forward(self, text, text_len):\n","\n","  #      text_emb = self.embedding(text)\n","\n","  #      packed_input = pack_padded_sequence(text_emb, text_len, batch_first=True, enforce_sorted=False)\n","  #      packed_output, _ = self.lstm(packed_input)\n","  #      output, _ = pad_packed_sequence(packed_output, batch_first=True)\n","\n","  #      out_forward = output[range(len(output)), text_len - 1, :self.dimension]\n","  #      out_reverse = output[:, 0, self.dimension:]\n","  #      out_reduced = torch.cat((out_forward, out_reverse), 1)\n","  #      text_fea = self.drop(out_reduced)\n","\n","  #      text_fea = self.fc(text_fea)\n","  #      text_fea = torch.squeeze(text_fea, 1)\n","  #      text_out = torch.sigmoid(text_fea)\n","\n","  #      return text_out"],"execution_count":22,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FDKE1z3KOAaV"},"source":["# Training"]},{"cell_type":"code","metadata":{"id":"2AUL7N-OPjYc","executionInfo":{"status":"ok","timestamp":1602834750709,"user_tz":-120,"elapsed":6253,"user":{"displayName":"Burcu Sayin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGwX32JPCvOoC3v5AsaJG8UrIAZoJ7VXcix4Coyg=s64","userId":"04171978679196166536"}}},"source":["def smooth_labels(crowd_labelList, conf0, conf1, conf2, alpha):\n","    y = np.column_stack((conf0.tolist(), conf1.tolist(), conf2.tolist()))\n","    for ind in range(len(y)):\n","        crowd_label = int(crowd_labelList[ind])\n","        for index in range(len(y[ind])):\n","          if index == crowd_label:\n","              y[ind][index] = 1 - alpha + alpha / num_classes\n","              pass\n","          else:\n","              y[ind][index] = alpha / num_classes\n","    return y\n","\n","class CrossEntropyLossSoft(nn.Module):\n","\n","    def __init__(self, weight=None):\n","        super(CrossEntropyLossSoft, self).__init__()\n","        self.weight = weight\n","\n","    def forward(self, pred, soft_targets):\n","        logsoftmax = nn.LogSoftmax()\n","        if self.weight is not None:\n","            return torch.mean(torch.sum(- soft_targets * self.weight * logsoftmax(pred), 1))\n","        else:\n","            return torch.mean(torch.sum(- soft_targets * logsoftmax(pred), 1))\n","\n","def ece_score(y_true, y_prob, n_bins=10):\n","    ece = ECE(n_bins)\n","    ece_val = ece.measure(y_prob, y_true)\n","\n","    return ece_val\n","\n","\n","def compute_val():\n","    loss_function = nn.CrossEntropyLoss()\n","    with torch.no_grad():\n","        model.eval()\n","        y_pred = []\n","        output_prob_val = []\n","        output_logits_val = []\n","        y_val_hard = []\n","        \n","        for ((text, text_len), labels, conf0, conf1, conf2), _ in valid_iter: \n","            y_val_hard.append(int(labels.item()))\n","            sent = text.to(device)\n","            sent_len = text_len.to(device)\n","            label = labels.to(device)\n","            output = model.forward(sent, text_len)\n","            logit, predicted = torch.max(output.data, 1)\n","            output_logits_val.append(output[0].cpu().tolist())\n","            output_prob_val.append(torch.sigmoid(output[0]).cpu().tolist())\n","            y_pred.append(predicted.item())\n","        loss_val = loss_function(torch.Tensor(output_logits_val), torch.LongTensor(y_val_hard)).item()\n","        model.train()\n","        ece_val = ece_score(np.array(y_val_hard), np.array(output_prob_val))\n","\n","        # check if binary or multi class classification\n","        num_classes = len(set(y_val_hard))\n","        if num_classes == 2:\n","            average = 'binary'\n","        else:\n","            average = 'macro'\n","        pre_val, rec_val, f1_val, _ = precision_recall_fscore_support(y_val_hard, y_pred, average=average, beta=1)\n","        _, _, f01_val, _ = precision_recall_fscore_support(y_val_hard, y_pred, average=average, beta=0.1)\n","        _, _, f10_val, _ = precision_recall_fscore_support(y_val_hard, y_pred, average=average, beta=10)\n","        print('Iteration: {}. Train Loss: {:1.5f}. Val Loss: {:1.5f}, F1: {:1.3f}, ECE: {:1.3f}, Precision: {:1.3f}, Recall: {:1.3f}'.\n","            format(i, loss.item(), loss_val, f1_val, ece_val, pre_val, rec_val))\n","        # print to result file\n","        with open(res_path, 'a') as f:\n","            res_i = '{}, {}, {}, {}, {}, {}, {}, {}, {}, {}\\n'.format(epoch, i, loss.item(), loss_val, pre_val, rec_val,\n","                                                                      f01_val, f1_val, f10_val, ece_val)\n","            f.write(res_i)"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"az5c6DaO9NFc","executionInfo":{"status":"ok","timestamp":1602835027425,"user_tz":-120,"elapsed":282935,"user":{"displayName":"Burcu Sayin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGwX32JPCvOoC3v5AsaJG8UrIAZoJ7VXcix4Coyg=s64","userId":"04171978679196166536"}},"outputId":"ad7c26ec-5959-4368-98b1-1a4f0418d83b","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# create log file\n","res_path += logfile_name\n","with open(res_path, 'w') as f:\n","    c = 'epoch, iter, loss_train, loss_val, pre_val, rec_val, f01_val, f1_val, f10_val, ece_val'\n","    f.write(c + '\\n')\n","\n","model = LSTM().to(device)\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","loss_function = CrossEntropyLossSoft(weight=class_weight.to(device))\n","train_loader = train_iter\n","valid_loader = valid_iter\n","\n","# training loop\n","model.train()\n","for epoch in range(max_epochs):\n","    print(\"EPOCH -- {}\".format(epoch))\n","    i = 0\n","    for ((text, text_len), labels, conf0, conf1, conf2), _ in train_loader:   \n","        optimizer.zero_grad()\n","        smoothed_labels = smooth_labels(labels, conf0, conf1, conf2, alpha)\n","        labels = torch.FloatTensor(smoothed_labels)\n","        labels = labels.to(device)\n","\n","        text = text.to(device)\n","        text_len = text_len.to(device)\n","        output = model.forward(text, text_len)\n","        loss = loss_function(output, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        if i % 100 == 0:\n","          compute_val()\n","\n","        i = i + 1"],"execution_count":24,"outputs":[{"output_type":"stream","text":["EPOCH -- 0\n","Iteration: 0. Train Loss: 1.91342. Val Loss: 1.12345, F1: 0.280, ECE: 0.262, Precision: 0.292, Recall: 0.307\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"},{"output_type":"stream","text":["EPOCH -- 1\n","Iteration: 0. Train Loss: 1.58855. Val Loss: 1.07414, F1: 0.355, ECE: 0.256, Precision: 0.614, Recall: 0.427\n","EPOCH -- 2\n","Iteration: 0. Train Loss: 1.27132. Val Loss: 0.93069, F1: 0.522, ECE: 0.185, Precision: 0.642, Recall: 0.547\n","EPOCH -- 3\n","Iteration: 0. Train Loss: 1.13838. Val Loss: 0.90622, F1: 0.515, ECE: 0.209, Precision: 0.632, Recall: 0.533\n","EPOCH -- 4\n","Iteration: 0. Train Loss: 1.10316. Val Loss: 0.90551, F1: 0.551, ECE: 0.163, Precision: 0.639, Recall: 0.573\n","EPOCH -- 5\n","Iteration: 0. Train Loss: 1.10697. Val Loss: 1.00018, F1: 0.533, ECE: 0.179, Precision: 0.641, Recall: 0.560\n","EPOCH -- 6\n","Iteration: 0. Train Loss: 1.08169. Val Loss: 0.92138, F1: 0.525, ECE: 0.200, Precision: 0.599, Recall: 0.547\n","EPOCH -- 7\n","Iteration: 0. Train Loss: 1.07911. Val Loss: 0.89833, F1: 0.581, ECE: 0.107, Precision: 0.615, Recall: 0.600\n","EPOCH -- 8\n","Iteration: 0. Train Loss: 1.08247. Val Loss: 0.90026, F1: 0.575, ECE: 0.116, Precision: 0.628, Recall: 0.600\n","EPOCH -- 9\n","Iteration: 0. Train Loss: 1.08807. Val Loss: 0.89456, F1: 0.570, ECE: 0.143, Precision: 0.636, Recall: 0.587\n","EPOCH -- 10\n","Iteration: 0. Train Loss: 1.07653. Val Loss: 0.94934, F1: 0.565, ECE: 0.137, Precision: 0.661, Recall: 0.587\n","EPOCH -- 11\n","Iteration: 0. Train Loss: 1.07917. Val Loss: 0.88818, F1: 0.605, ECE: 0.110, Precision: 0.670, Recall: 0.627\n","EPOCH -- 12\n","Iteration: 0. Train Loss: 1.06880. Val Loss: 0.89107, F1: 0.581, ECE: 0.121, Precision: 0.630, Recall: 0.600\n","EPOCH -- 13\n","Iteration: 0. Train Loss: 1.07338. Val Loss: 0.89289, F1: 0.595, ECE: 0.113, Precision: 0.654, Recall: 0.613\n","EPOCH -- 14\n","Iteration: 0. Train Loss: 1.06752. Val Loss: 0.90526, F1: 0.581, ECE: 0.116, Precision: 0.640, Recall: 0.600\n","EPOCH -- 15\n","Iteration: 0. Train Loss: 1.06772. Val Loss: 0.89783, F1: 0.583, ECE: 0.126, Precision: 0.640, Recall: 0.600\n","EPOCH -- 16\n","Iteration: 0. Train Loss: 1.07169. Val Loss: 0.92321, F1: 0.582, ECE: 0.106, Precision: 0.671, Recall: 0.600\n","EPOCH -- 17\n","Iteration: 0. Train Loss: 1.07183. Val Loss: 0.97267, F1: 0.538, ECE: 0.159, Precision: 0.652, Recall: 0.560\n","EPOCH -- 18\n","Iteration: 0. Train Loss: 1.07438. Val Loss: 0.98229, F1: 0.506, ECE: 0.186, Precision: 0.632, Recall: 0.533\n","EPOCH -- 19\n","Iteration: 0. Train Loss: 1.07161. Val Loss: 0.98027, F1: 0.504, ECE: 0.191, Precision: 0.621, Recall: 0.533\n","EPOCH -- 20\n","Iteration: 0. Train Loss: 1.06814. Val Loss: 0.96783, F1: 0.547, ECE: 0.170, Precision: 0.650, Recall: 0.573\n","EPOCH -- 21\n","Iteration: 0. Train Loss: 1.07434. Val Loss: 0.93161, F1: 0.586, ECE: 0.105, Precision: 0.665, Recall: 0.613\n","EPOCH -- 22\n","Iteration: 0. Train Loss: 1.07663. Val Loss: 0.90962, F1: 0.586, ECE: 0.100, Precision: 0.637, Recall: 0.613\n","EPOCH -- 23\n","Iteration: 0. Train Loss: 1.07185. Val Loss: 0.89811, F1: 0.586, ECE: 0.105, Precision: 0.654, Recall: 0.613\n","EPOCH -- 24\n","Iteration: 0. Train Loss: 1.07154. Val Loss: 0.89981, F1: 0.585, ECE: 0.114, Precision: 0.653, Recall: 0.613\n","EPOCH -- 25\n","Iteration: 0. Train Loss: 1.06966. Val Loss: 0.88900, F1: 0.605, ECE: 0.086, Precision: 0.649, Recall: 0.627\n","EPOCH -- 26\n","Iteration: 0. Train Loss: 1.08129. Val Loss: 0.90250, F1: 0.551, ECE: 0.110, Precision: 0.583, Recall: 0.573\n","EPOCH -- 27\n","Iteration: 0. Train Loss: 1.07987. Val Loss: 0.93344, F1: 0.530, ECE: 0.141, Precision: 0.622, Recall: 0.547\n","EPOCH -- 28\n","Iteration: 0. Train Loss: 1.09516. Val Loss: 1.01947, F1: 0.505, ECE: 0.186, Precision: 0.675, Recall: 0.533\n","EPOCH -- 29\n","Iteration: 0. Train Loss: 1.07757. Val Loss: 1.05026, F1: 0.445, ECE: 0.239, Precision: 0.626, Recall: 0.493\n","EPOCH -- 30\n","Iteration: 0. Train Loss: 1.07883. Val Loss: 0.94752, F1: 0.559, ECE: 0.128, Precision: 0.688, Recall: 0.587\n","EPOCH -- 31\n","Iteration: 0. Train Loss: 1.07585. Val Loss: 0.89495, F1: 0.587, ECE: 0.131, Precision: 0.670, Recall: 0.613\n","EPOCH -- 32\n","Iteration: 0. Train Loss: 1.06862. Val Loss: 0.89039, F1: 0.564, ECE: 0.145, Precision: 0.668, Recall: 0.587\n","EPOCH -- 33\n","Iteration: 0. Train Loss: 1.06689. Val Loss: 0.89796, F1: 0.576, ECE: 0.114, Precision: 0.680, Recall: 0.600\n","EPOCH -- 34\n","Iteration: 0. Train Loss: 1.06726. Val Loss: 0.90111, F1: 0.576, ECE: 0.119, Precision: 0.680, Recall: 0.600\n","EPOCH -- 35\n","Iteration: 0. Train Loss: 1.06643. Val Loss: 0.90961, F1: 0.576, ECE: 0.100, Precision: 0.680, Recall: 0.600\n","EPOCH -- 36\n","Iteration: 0. Train Loss: 1.06803. Val Loss: 0.92094, F1: 0.575, ECE: 0.121, Precision: 0.684, Recall: 0.600\n","EPOCH -- 37\n","Iteration: 0. Train Loss: 1.06566. Val Loss: 0.92252, F1: 0.575, ECE: 0.123, Precision: 0.684, Recall: 0.600\n","EPOCH -- 38\n","Iteration: 0. Train Loss: 1.06650. Val Loss: 0.92326, F1: 0.593, ECE: 0.117, Precision: 0.693, Recall: 0.613\n","EPOCH -- 39\n","Iteration: 0. Train Loss: 1.06837. Val Loss: 0.92064, F1: 0.575, ECE: 0.139, Precision: 0.684, Recall: 0.600\n","EPOCH -- 40\n","Iteration: 0. Train Loss: 1.06779. Val Loss: 0.91081, F1: 0.575, ECE: 0.143, Precision: 0.684, Recall: 0.600\n","EPOCH -- 41\n","Iteration: 0. Train Loss: 1.06818. Val Loss: 0.91349, F1: 0.575, ECE: 0.137, Precision: 0.684, Recall: 0.600\n","EPOCH -- 42\n","Iteration: 0. Train Loss: 1.07137. Val Loss: 0.90966, F1: 0.575, ECE: 0.136, Precision: 0.684, Recall: 0.600\n","EPOCH -- 43\n","Iteration: 0. Train Loss: 1.06329. Val Loss: 0.91612, F1: 0.575, ECE: 0.133, Precision: 0.684, Recall: 0.600\n","EPOCH -- 44\n","Iteration: 0. Train Loss: 1.06497. Val Loss: 0.90746, F1: 0.587, ECE: 0.136, Precision: 0.693, Recall: 0.613\n","EPOCH -- 45\n","Iteration: 0. Train Loss: 1.06513. Val Loss: 0.90961, F1: 0.587, ECE: 0.117, Precision: 0.693, Recall: 0.613\n","EPOCH -- 46\n","Iteration: 0. Train Loss: 1.06659. Val Loss: 0.90657, F1: 0.587, ECE: 0.120, Precision: 0.693, Recall: 0.613\n","EPOCH -- 47\n","Iteration: 0. Train Loss: 1.06962. Val Loss: 0.90554, F1: 0.587, ECE: 0.097, Precision: 0.693, Recall: 0.613\n","EPOCH -- 48\n","Iteration: 0. Train Loss: 1.06345. Val Loss: 0.90665, F1: 0.576, ECE: 0.119, Precision: 0.680, Recall: 0.600\n","EPOCH -- 49\n","Iteration: 0. Train Loss: 1.06343. Val Loss: 0.90170, F1: 0.587, ECE: 0.121, Precision: 0.693, Recall: 0.613\n","EPOCH -- 50\n","Iteration: 0. Train Loss: 1.06452. Val Loss: 0.90904, F1: 0.576, ECE: 0.118, Precision: 0.657, Recall: 0.600\n","EPOCH -- 51\n","Iteration: 0. Train Loss: 1.06408. Val Loss: 0.92243, F1: 0.576, ECE: 0.100, Precision: 0.690, Recall: 0.600\n","EPOCH -- 52\n","Iteration: 0. Train Loss: 1.06323. Val Loss: 0.91989, F1: 0.576, ECE: 0.118, Precision: 0.690, Recall: 0.600\n","EPOCH -- 53\n","Iteration: 0. Train Loss: 1.06603. Val Loss: 0.92020, F1: 0.554, ECE: 0.146, Precision: 0.670, Recall: 0.587\n","EPOCH -- 54\n","Iteration: 0. Train Loss: 1.06926. Val Loss: 0.92821, F1: 0.559, ECE: 0.142, Precision: 0.688, Recall: 0.587\n","EPOCH -- 55\n","Iteration: 0. Train Loss: 1.06732. Val Loss: 0.92464, F1: 0.555, ECE: 0.145, Precision: 0.675, Recall: 0.587\n","EPOCH -- 56\n","Iteration: 0. Train Loss: 1.06893. Val Loss: 0.91124, F1: 0.554, ECE: 0.141, Precision: 0.670, Recall: 0.587\n","EPOCH -- 57\n","Iteration: 0. Train Loss: 1.06591. Val Loss: 0.90619, F1: 0.543, ECE: 0.190, Precision: 0.658, Recall: 0.573\n","EPOCH -- 58\n","Iteration: 0. Train Loss: 1.06946. Val Loss: 0.92920, F1: 0.557, ECE: 0.130, Precision: 0.710, Recall: 0.587\n","EPOCH -- 59\n","Iteration: 0. Train Loss: 1.06781. Val Loss: 0.95277, F1: 0.564, ECE: 0.140, Precision: 0.682, Recall: 0.587\n","EPOCH -- 60\n","Iteration: 0. Train Loss: 1.06593. Val Loss: 0.93826, F1: 0.554, ECE: 0.149, Precision: 0.670, Recall: 0.587\n","EPOCH -- 61\n","Iteration: 0. Train Loss: 1.07307. Val Loss: 0.91116, F1: 0.564, ECE: 0.145, Precision: 0.668, Recall: 0.587\n","EPOCH -- 62\n","Iteration: 0. Train Loss: 1.06861. Val Loss: 0.91861, F1: 0.564, ECE: 0.148, Precision: 0.672, Recall: 0.587\n","EPOCH -- 63\n","Iteration: 0. Train Loss: 1.07629. Val Loss: 0.93693, F1: 0.559, ECE: 0.141, Precision: 0.681, Recall: 0.587\n","EPOCH -- 64\n","Iteration: 0. Train Loss: 1.06716. Val Loss: 0.91963, F1: 0.564, ECE: 0.119, Precision: 0.672, Recall: 0.587\n","EPOCH -- 65\n","Iteration: 0. Train Loss: 1.06817. Val Loss: 0.90098, F1: 0.582, ECE: 0.080, Precision: 0.672, Recall: 0.600\n","EPOCH -- 66\n","Iteration: 0. Train Loss: 1.06841. Val Loss: 0.90245, F1: 0.550, ECE: 0.148, Precision: 0.625, Recall: 0.573\n","EPOCH -- 67\n","Iteration: 0. Train Loss: 1.06725. Val Loss: 0.90470, F1: 0.564, ECE: 0.126, Precision: 0.619, Recall: 0.587\n","EPOCH -- 68\n","Iteration: 0. Train Loss: 1.07597. Val Loss: 0.90904, F1: 0.563, ECE: 0.110, Precision: 0.663, Recall: 0.587\n","EPOCH -- 69\n","Iteration: 0. Train Loss: 1.06751. Val Loss: 0.91834, F1: 0.556, ECE: 0.143, Precision: 0.707, Recall: 0.587\n","EPOCH -- 70\n","Iteration: 0. Train Loss: 1.06965. Val Loss: 0.93556, F1: 0.534, ECE: 0.182, Precision: 0.694, Recall: 0.560\n","EPOCH -- 71\n","Iteration: 0. Train Loss: 1.06622. Val Loss: 0.92974, F1: 0.546, ECE: 0.166, Precision: 0.702, Recall: 0.573\n","EPOCH -- 72\n","Iteration: 0. Train Loss: 1.06746. Val Loss: 0.92621, F1: 0.533, ECE: 0.168, Precision: 0.650, Recall: 0.560\n","EPOCH -- 73\n","Iteration: 0. Train Loss: 1.07258. Val Loss: 0.92437, F1: 0.532, ECE: 0.181, Precision: 0.646, Recall: 0.560\n","EPOCH -- 74\n","Iteration: 0. Train Loss: 1.07008. Val Loss: 0.93041, F1: 0.521, ECE: 0.164, Precision: 0.635, Recall: 0.547\n","EPOCH -- 75\n","Iteration: 0. Train Loss: 1.06678. Val Loss: 0.92661, F1: 0.521, ECE: 0.170, Precision: 0.635, Recall: 0.547\n","EPOCH -- 76\n","Iteration: 0. Train Loss: 1.06496. Val Loss: 0.91041, F1: 0.554, ECE: 0.130, Precision: 0.661, Recall: 0.587\n","EPOCH -- 77\n","Iteration: 0. Train Loss: 1.06493. Val Loss: 0.91037, F1: 0.551, ECE: 0.157, Precision: 0.650, Recall: 0.573\n","EPOCH -- 78\n","Iteration: 0. Train Loss: 1.06495. Val Loss: 0.90585, F1: 0.574, ECE: 0.116, Precision: 0.644, Recall: 0.600\n","EPOCH -- 79\n","Iteration: 0. Train Loss: 1.06836. Val Loss: 0.90809, F1: 0.575, ECE: 0.128, Precision: 0.649, Recall: 0.600\n","EPOCH -- 80\n","Iteration: 0. Train Loss: 1.06489. Val Loss: 0.90822, F1: 0.551, ECE: 0.171, Precision: 0.624, Recall: 0.573\n","EPOCH -- 81\n","Iteration: 0. Train Loss: 1.06538. Val Loss: 0.91008, F1: 0.565, ECE: 0.160, Precision: 0.700, Recall: 0.587\n","EPOCH -- 82\n","Iteration: 0. Train Loss: 1.06616. Val Loss: 0.93244, F1: 0.546, ECE: 0.152, Precision: 0.662, Recall: 0.573\n","EPOCH -- 83\n","Iteration: 0. Train Loss: 1.06544. Val Loss: 0.93278, F1: 0.545, ECE: 0.145, Precision: 0.658, Recall: 0.573\n","EPOCH -- 84\n","Iteration: 0. Train Loss: 1.06583. Val Loss: 0.91717, F1: 0.557, ECE: 0.146, Precision: 0.667, Recall: 0.587\n","EPOCH -- 85\n","Iteration: 0. Train Loss: 1.06435. Val Loss: 0.92060, F1: 0.545, ECE: 0.138, Precision: 0.658, Recall: 0.573\n","EPOCH -- 86\n","Iteration: 0. Train Loss: 1.06427. Val Loss: 0.92519, F1: 0.545, ECE: 0.122, Precision: 0.658, Recall: 0.573\n","EPOCH -- 87\n","Iteration: 0. Train Loss: 1.06220. Val Loss: 0.93646, F1: 0.533, ECE: 0.137, Precision: 0.650, Recall: 0.560\n","EPOCH -- 88\n","Iteration: 0. Train Loss: 1.06274. Val Loss: 0.92693, F1: 0.544, ECE: 0.167, Precision: 0.652, Recall: 0.573\n","EPOCH -- 89\n","Iteration: 0. Train Loss: 1.06325. Val Loss: 0.91285, F1: 0.566, ECE: 0.130, Precision: 0.669, Recall: 0.600\n","EPOCH -- 90\n","Iteration: 0. Train Loss: 1.06179. Val Loss: 0.91625, F1: 0.554, ECE: 0.120, Precision: 0.658, Recall: 0.587\n","EPOCH -- 91\n","Iteration: 0. Train Loss: 1.06406. Val Loss: 0.91906, F1: 0.543, ECE: 0.157, Precision: 0.652, Recall: 0.573\n","EPOCH -- 92\n","Iteration: 0. Train Loss: 1.06429. Val Loss: 0.91857, F1: 0.567, ECE: 0.117, Precision: 0.672, Recall: 0.600\n","EPOCH -- 93\n","Iteration: 0. Train Loss: 1.06531. Val Loss: 0.92706, F1: 0.544, ECE: 0.169, Precision: 0.695, Recall: 0.573\n","EPOCH -- 94\n","Iteration: 0. Train Loss: 1.06518. Val Loss: 0.90101, F1: 0.555, ECE: 0.150, Precision: 0.660, Recall: 0.587\n","EPOCH -- 95\n","Iteration: 0. Train Loss: 1.06538. Val Loss: 0.91325, F1: 0.567, ECE: 0.129, Precision: 0.675, Recall: 0.600\n","EPOCH -- 96\n","Iteration: 0. Train Loss: 1.06784. Val Loss: 0.93427, F1: 0.568, ECE: 0.124, Precision: 0.679, Recall: 0.600\n","EPOCH -- 97\n","Iteration: 0. Train Loss: 1.06884. Val Loss: 0.94040, F1: 0.557, ECE: 0.139, Precision: 0.714, Recall: 0.587\n","EPOCH -- 98\n","Iteration: 0. Train Loss: 1.06960. Val Loss: 0.92344, F1: 0.566, ECE: 0.120, Precision: 0.718, Recall: 0.600\n","EPOCH -- 99\n","Iteration: 0. Train Loss: 1.06631. Val Loss: 0.90970, F1: 0.555, ECE: 0.143, Precision: 0.660, Recall: 0.587\n","EPOCH -- 100\n","Iteration: 0. Train Loss: 1.06330. Val Loss: 0.91434, F1: 0.566, ECE: 0.137, Precision: 0.670, Recall: 0.600\n","EPOCH -- 101\n","Iteration: 0. Train Loss: 1.06338. Val Loss: 0.93361, F1: 0.555, ECE: 0.135, Precision: 0.661, Recall: 0.587\n","EPOCH -- 102\n","Iteration: 0. Train Loss: 1.06681. Val Loss: 0.93007, F1: 0.555, ECE: 0.128, Precision: 0.661, Recall: 0.587\n","EPOCH -- 103\n","Iteration: 0. Train Loss: 1.06655. Val Loss: 0.91869, F1: 0.555, ECE: 0.133, Precision: 0.661, Recall: 0.587\n","EPOCH -- 104\n","Iteration: 0. Train Loss: 1.06460. Val Loss: 0.91472, F1: 0.555, ECE: 0.118, Precision: 0.660, Recall: 0.587\n","EPOCH -- 105\n","Iteration: 0. Train Loss: 1.06407. Val Loss: 0.91409, F1: 0.554, ECE: 0.136, Precision: 0.659, Recall: 0.587\n","EPOCH -- 106\n","Iteration: 0. Train Loss: 1.06107. Val Loss: 0.92962, F1: 0.532, ECE: 0.155, Precision: 0.640, Recall: 0.560\n","EPOCH -- 107\n","Iteration: 0. Train Loss: 1.06234. Val Loss: 0.92006, F1: 0.532, ECE: 0.179, Precision: 0.641, Recall: 0.560\n","EPOCH -- 108\n","Iteration: 0. Train Loss: 1.06898. Val Loss: 0.90872, F1: 0.554, ECE: 0.136, Precision: 0.659, Recall: 0.587\n","EPOCH -- 109\n","Iteration: 0. Train Loss: 1.06596. Val Loss: 0.92798, F1: 0.531, ECE: 0.168, Precision: 0.639, Recall: 0.560\n","EPOCH -- 110\n","Iteration: 0. Train Loss: 1.06685. Val Loss: 0.92996, F1: 0.543, ECE: 0.152, Precision: 0.693, Recall: 0.573\n","EPOCH -- 111\n","Iteration: 0. Train Loss: 1.07012. Val Loss: 0.93479, F1: 0.566, ECE: 0.148, Precision: 0.713, Recall: 0.600\n","EPOCH -- 112\n","Iteration: 0. Train Loss: 1.06715. Val Loss: 0.92920, F1: 0.543, ECE: 0.176, Precision: 0.693, Recall: 0.573\n","EPOCH -- 113\n","Iteration: 0. Train Loss: 1.06421. Val Loss: 0.91449, F1: 0.555, ECE: 0.145, Precision: 0.702, Recall: 0.587\n","EPOCH -- 114\n","Iteration: 0. Train Loss: 1.06819. Val Loss: 0.93028, F1: 0.544, ECE: 0.152, Precision: 0.695, Recall: 0.573\n","EPOCH -- 115\n","Iteration: 0. Train Loss: 1.06663. Val Loss: 0.93691, F1: 0.542, ECE: 0.140, Precision: 0.695, Recall: 0.573\n","EPOCH -- 116\n","Iteration: 0. Train Loss: 1.07068. Val Loss: 0.92671, F1: 0.554, ECE: 0.136, Precision: 0.663, Recall: 0.587\n","EPOCH -- 117\n","Iteration: 0. Train Loss: 1.06356. Val Loss: 0.92030, F1: 0.554, ECE: 0.138, Precision: 0.659, Recall: 0.587\n","EPOCH -- 118\n","Iteration: 0. Train Loss: 1.06330. Val Loss: 0.91784, F1: 0.543, ECE: 0.166, Precision: 0.649, Recall: 0.573\n","EPOCH -- 119\n","Iteration: 0. Train Loss: 1.06857. Val Loss: 0.92657, F1: 0.555, ECE: 0.139, Precision: 0.661, Recall: 0.587\n","EPOCH -- 120\n","Iteration: 0. Train Loss: 1.06823. Val Loss: 0.92678, F1: 0.543, ECE: 0.148, Precision: 0.648, Recall: 0.573\n","EPOCH -- 121\n","Iteration: 0. Train Loss: 1.06826. Val Loss: 0.92423, F1: 0.553, ECE: 0.134, Precision: 0.628, Recall: 0.587\n","EPOCH -- 122\n","Iteration: 0. Train Loss: 1.06605. Val Loss: 0.92472, F1: 0.554, ECE: 0.140, Precision: 0.658, Recall: 0.587\n","EPOCH -- 123\n","Iteration: 0. Train Loss: 1.06685. Val Loss: 0.92847, F1: 0.565, ECE: 0.117, Precision: 0.668, Recall: 0.600\n","EPOCH -- 124\n","Iteration: 0. Train Loss: 1.06214. Val Loss: 0.93548, F1: 0.554, ECE: 0.146, Precision: 0.658, Recall: 0.587\n","EPOCH -- 125\n","Iteration: 0. Train Loss: 1.06560. Val Loss: 0.93851, F1: 0.532, ECE: 0.170, Precision: 0.640, Recall: 0.560\n","EPOCH -- 126\n","Iteration: 0. Train Loss: 1.06451. Val Loss: 0.93508, F1: 0.544, ECE: 0.164, Precision: 0.691, Recall: 0.573\n","EPOCH -- 127\n","Iteration: 0. Train Loss: 1.06784. Val Loss: 0.95346, F1: 0.544, ECE: 0.141, Precision: 0.655, Recall: 0.573\n","EPOCH -- 128\n","Iteration: 0. Train Loss: 1.06933. Val Loss: 0.96755, F1: 0.532, ECE: 0.156, Precision: 0.641, Recall: 0.560\n","EPOCH -- 129\n","Iteration: 0. Train Loss: 1.06526. Val Loss: 0.96815, F1: 0.543, ECE: 0.143, Precision: 0.650, Recall: 0.573\n","EPOCH -- 130\n","Iteration: 0. Train Loss: 1.06599. Val Loss: 0.95380, F1: 0.543, ECE: 0.167, Precision: 0.652, Recall: 0.573\n","EPOCH -- 131\n","Iteration: 0. Train Loss: 1.06569. Val Loss: 0.92533, F1: 0.544, ECE: 0.178, Precision: 0.650, Recall: 0.573\n","EPOCH -- 132\n","Iteration: 0. Train Loss: 1.06607. Val Loss: 0.93140, F1: 0.532, ECE: 0.169, Precision: 0.639, Recall: 0.560\n","EPOCH -- 133\n","Iteration: 0. Train Loss: 1.06563. Val Loss: 0.93596, F1: 0.543, ECE: 0.165, Precision: 0.648, Recall: 0.573\n","EPOCH -- 134\n","Iteration: 0. Train Loss: 1.06380. Val Loss: 0.94241, F1: 0.555, ECE: 0.164, Precision: 0.661, Recall: 0.587\n","EPOCH -- 135\n","Iteration: 0. Train Loss: 1.06263. Val Loss: 0.93783, F1: 0.543, ECE: 0.170, Precision: 0.648, Recall: 0.573\n","EPOCH -- 136\n","Iteration: 0. Train Loss: 1.06292. Val Loss: 0.92913, F1: 0.554, ECE: 0.156, Precision: 0.628, Recall: 0.587\n","EPOCH -- 137\n","Iteration: 0. Train Loss: 1.06357. Val Loss: 0.93213, F1: 0.521, ECE: 0.189, Precision: 0.672, Recall: 0.547\n","EPOCH -- 138\n","Iteration: 0. Train Loss: 1.06483. Val Loss: 0.94337, F1: 0.532, ECE: 0.181, Precision: 0.681, Recall: 0.560\n","EPOCH -- 139\n","Iteration: 0. Train Loss: 1.06510. Val Loss: 0.94113, F1: 0.565, ECE: 0.126, Precision: 0.710, Recall: 0.600\n","EPOCH -- 140\n","Iteration: 0. Train Loss: 1.06658. Val Loss: 0.95070, F1: 0.565, ECE: 0.120, Precision: 0.668, Recall: 0.600\n","EPOCH -- 141\n","Iteration: 0. Train Loss: 1.06165. Val Loss: 0.93839, F1: 0.566, ECE: 0.139, Precision: 0.711, Recall: 0.600\n","EPOCH -- 142\n","Iteration: 0. Train Loss: 1.06505. Val Loss: 0.93002, F1: 0.554, ECE: 0.176, Precision: 0.658, Recall: 0.587\n","EPOCH -- 143\n","Iteration: 0. Train Loss: 1.06255. Val Loss: 0.93927, F1: 0.543, ECE: 0.189, Precision: 0.649, Recall: 0.573\n","EPOCH -- 144\n","Iteration: 0. Train Loss: 1.06253. Val Loss: 0.94672, F1: 0.554, ECE: 0.140, Precision: 0.661, Recall: 0.587\n","EPOCH -- 145\n","Iteration: 0. Train Loss: 1.06510. Val Loss: 0.96880, F1: 0.543, ECE: 0.143, Precision: 0.650, Recall: 0.573\n","EPOCH -- 146\n","Iteration: 0. Train Loss: 1.06396. Val Loss: 0.95774, F1: 0.543, ECE: 0.143, Precision: 0.650, Recall: 0.573\n","EPOCH -- 147\n","Iteration: 0. Train Loss: 1.06835. Val Loss: 0.93445, F1: 0.543, ECE: 0.191, Precision: 0.648, Recall: 0.573\n","EPOCH -- 148\n","Iteration: 0. Train Loss: 1.06326. Val Loss: 0.93287, F1: 0.555, ECE: 0.164, Precision: 0.659, Recall: 0.587\n","EPOCH -- 149\n","Iteration: 0. Train Loss: 1.06208. Val Loss: 0.92284, F1: 0.543, ECE: 0.161, Precision: 0.649, Recall: 0.573\n","EPOCH -- 150\n","Iteration: 0. Train Loss: 1.06780. Val Loss: 0.94295, F1: 0.520, ECE: 0.193, Precision: 0.629, Recall: 0.547\n","EPOCH -- 151\n","Iteration: 0. Train Loss: 1.06415. Val Loss: 0.94404, F1: 0.533, ECE: 0.178, Precision: 0.683, Recall: 0.560\n","EPOCH -- 152\n","Iteration: 0. Train Loss: 1.06227. Val Loss: 0.94236, F1: 0.543, ECE: 0.139, Precision: 0.692, Recall: 0.573\n","EPOCH -- 153\n","Iteration: 0. Train Loss: 1.06391. Val Loss: 0.94015, F1: 0.531, ECE: 0.181, Precision: 0.639, Recall: 0.560\n","EPOCH -- 154\n","Iteration: 0. Train Loss: 1.06691. Val Loss: 0.93245, F1: 0.543, ECE: 0.133, Precision: 0.649, Recall: 0.573\n","EPOCH -- 155\n","Iteration: 0. Train Loss: 1.06695. Val Loss: 0.94857, F1: 0.520, ECE: 0.172, Precision: 0.629, Recall: 0.547\n","EPOCH -- 156\n","Iteration: 0. Train Loss: 1.06692. Val Loss: 0.96777, F1: 0.554, ECE: 0.198, Precision: 0.702, Recall: 0.587\n","EPOCH -- 157\n","Iteration: 0. Train Loss: 1.06348. Val Loss: 0.95525, F1: 0.554, ECE: 0.140, Precision: 0.702, Recall: 0.587\n","EPOCH -- 158\n","Iteration: 0. Train Loss: 1.06353. Val Loss: 0.94227, F1: 0.543, ECE: 0.174, Precision: 0.691, Recall: 0.573\n","EPOCH -- 159\n","Iteration: 0. Train Loss: 1.06268. Val Loss: 0.93573, F1: 0.554, ECE: 0.173, Precision: 0.658, Recall: 0.587\n","EPOCH -- 160\n","Iteration: 0. Train Loss: 1.06632. Val Loss: 0.93407, F1: 0.553, ECE: 0.152, Precision: 0.630, Recall: 0.587\n","EPOCH -- 161\n","Iteration: 0. Train Loss: 1.06216. Val Loss: 0.95678, F1: 0.543, ECE: 0.153, Precision: 0.650, Recall: 0.573\n","EPOCH -- 162\n","Iteration: 0. Train Loss: 1.06350. Val Loss: 0.94898, F1: 0.554, ECE: 0.158, Precision: 0.658, Recall: 0.587\n","EPOCH -- 163\n","Iteration: 0. Train Loss: 1.06333. Val Loss: 0.95016, F1: 0.543, ECE: 0.183, Precision: 0.618, Recall: 0.573\n","EPOCH -- 164\n","Iteration: 0. Train Loss: 1.06686. Val Loss: 0.94573, F1: 0.543, ECE: 0.183, Precision: 0.618, Recall: 0.573\n","EPOCH -- 165\n","Iteration: 0. Train Loss: 1.06289. Val Loss: 0.94760, F1: 0.531, ECE: 0.201, Precision: 0.608, Recall: 0.560\n","EPOCH -- 166\n","Iteration: 0. Train Loss: 1.06344. Val Loss: 0.94854, F1: 0.531, ECE: 0.193, Precision: 0.609, Recall: 0.560\n","EPOCH -- 167\n","Iteration: 0. Train Loss: 1.06489. Val Loss: 0.94478, F1: 0.531, ECE: 0.184, Precision: 0.609, Recall: 0.560\n","EPOCH -- 168\n","Iteration: 0. Train Loss: 1.06295. Val Loss: 0.94361, F1: 0.520, ECE: 0.193, Precision: 0.598, Recall: 0.547\n","EPOCH -- 169\n","Iteration: 0. Train Loss: 1.06190. Val Loss: 0.94323, F1: 0.532, ECE: 0.174, Precision: 0.609, Recall: 0.560\n","EPOCH -- 170\n","Iteration: 0. Train Loss: 1.06320. Val Loss: 0.94150, F1: 0.532, ECE: 0.170, Precision: 0.609, Recall: 0.560\n","EPOCH -- 171\n","Iteration: 0. Train Loss: 1.06116. Val Loss: 0.95229, F1: 0.531, ECE: 0.181, Precision: 0.608, Recall: 0.560\n","EPOCH -- 172\n","Iteration: 0. Train Loss: 1.06333. Val Loss: 0.95121, F1: 0.554, ECE: 0.133, Precision: 0.659, Recall: 0.587\n","EPOCH -- 173\n","Iteration: 0. Train Loss: 1.06069. Val Loss: 0.94610, F1: 0.542, ECE: 0.168, Precision: 0.648, Recall: 0.573\n","EPOCH -- 174\n","Iteration: 0. Train Loss: 1.06374. Val Loss: 0.94717, F1: 0.531, ECE: 0.185, Precision: 0.608, Recall: 0.560\n","EPOCH -- 175\n","Iteration: 0. Train Loss: 1.06277. Val Loss: 0.94178, F1: 0.532, ECE: 0.182, Precision: 0.639, Recall: 0.560\n","EPOCH -- 176\n","Iteration: 0. Train Loss: 1.06335. Val Loss: 0.94990, F1: 0.532, ECE: 0.167, Precision: 0.640, Recall: 0.560\n","EPOCH -- 177\n","Iteration: 0. Train Loss: 1.06363. Val Loss: 0.95593, F1: 0.543, ECE: 0.148, Precision: 0.690, Recall: 0.573\n","EPOCH -- 178\n","Iteration: 0. Train Loss: 1.06516. Val Loss: 0.95698, F1: 0.543, ECE: 0.163, Precision: 0.692, Recall: 0.573\n","EPOCH -- 179\n","Iteration: 0. Train Loss: 1.06363. Val Loss: 0.94188, F1: 0.542, ECE: 0.177, Precision: 0.649, Recall: 0.573\n","EPOCH -- 180\n","Iteration: 0. Train Loss: 1.06487. Val Loss: 0.93216, F1: 0.542, ECE: 0.200, Precision: 0.648, Recall: 0.573\n","EPOCH -- 181\n","Iteration: 0. Train Loss: 1.06400. Val Loss: 0.94349, F1: 0.542, ECE: 0.195, Precision: 0.648, Recall: 0.573\n","EPOCH -- 182\n","Iteration: 0. Train Loss: 1.06165. Val Loss: 0.94616, F1: 0.542, ECE: 0.199, Precision: 0.648, Recall: 0.573\n","EPOCH -- 183\n","Iteration: 0. Train Loss: 1.06300. Val Loss: 0.92713, F1: 0.573, ECE: 0.145, Precision: 0.643, Recall: 0.600\n","EPOCH -- 184\n","Iteration: 0. Train Loss: 1.06250. Val Loss: 0.95251, F1: 0.554, ECE: 0.168, Precision: 0.700, Recall: 0.587\n","EPOCH -- 185\n","Iteration: 0. Train Loss: 1.06357. Val Loss: 0.95164, F1: 0.553, ECE: 0.143, Precision: 0.659, Recall: 0.587\n","EPOCH -- 186\n","Iteration: 0. Train Loss: 1.06700. Val Loss: 0.91905, F1: 0.577, ECE: 0.157, Precision: 0.720, Recall: 0.613\n","EPOCH -- 187\n","Iteration: 0. Train Loss: 1.06269. Val Loss: 0.92644, F1: 0.543, ECE: 0.176, Precision: 0.690, Recall: 0.573\n","EPOCH -- 188\n","Iteration: 0. Train Loss: 1.06093. Val Loss: 0.92167, F1: 0.533, ECE: 0.185, Precision: 0.683, Recall: 0.560\n","EPOCH -- 189\n","Iteration: 0. Train Loss: 1.06198. Val Loss: 0.92814, F1: 0.521, ECE: 0.210, Precision: 0.631, Recall: 0.547\n","EPOCH -- 190\n","Iteration: 0. Train Loss: 1.06713. Val Loss: 0.94332, F1: 0.543, ECE: 0.190, Precision: 0.690, Recall: 0.573\n","EPOCH -- 191\n","Iteration: 0. Train Loss: 1.06288. Val Loss: 0.93340, F1: 0.532, ECE: 0.190, Precision: 0.639, Recall: 0.560\n","EPOCH -- 192\n","Iteration: 0. Train Loss: 1.06501. Val Loss: 0.92213, F1: 0.533, ECE: 0.165, Precision: 0.682, Recall: 0.560\n","EPOCH -- 193\n","Iteration: 0. Train Loss: 1.06242. Val Loss: 0.92693, F1: 0.543, ECE: 0.158, Precision: 0.648, Recall: 0.573\n","EPOCH -- 194\n","Iteration: 0. Train Loss: 1.06308. Val Loss: 0.93138, F1: 0.543, ECE: 0.191, Precision: 0.690, Recall: 0.573\n","EPOCH -- 195\n","Iteration: 0. Train Loss: 1.06328. Val Loss: 0.94100, F1: 0.533, ECE: 0.178, Precision: 0.683, Recall: 0.560\n","EPOCH -- 196\n","Iteration: 0. Train Loss: 1.06059. Val Loss: 0.94449, F1: 0.532, ECE: 0.191, Precision: 0.640, Recall: 0.560\n","EPOCH -- 197\n","Iteration: 0. Train Loss: 1.06352. Val Loss: 0.93681, F1: 0.544, ECE: 0.183, Precision: 0.691, Recall: 0.573\n","EPOCH -- 198\n","Iteration: 0. Train Loss: 1.06299. Val Loss: 0.93907, F1: 0.522, ECE: 0.217, Precision: 0.632, Recall: 0.547\n","EPOCH -- 199\n","Iteration: 0. Train Loss: 1.06402. Val Loss: 0.96852, F1: 0.521, ECE: 0.199, Precision: 0.577, Recall: 0.547\n","EPOCH -- 200\n","Iteration: 0. Train Loss: 1.06395. Val Loss: 0.96721, F1: 0.532, ECE: 0.188, Precision: 0.587, Recall: 0.560\n","EPOCH -- 201\n","Iteration: 0. Train Loss: 1.06200. Val Loss: 0.97656, F1: 0.544, ECE: 0.198, Precision: 0.620, Recall: 0.573\n","EPOCH -- 202\n","Iteration: 0. Train Loss: 1.06532. Val Loss: 0.97410, F1: 0.520, ECE: 0.217, Precision: 0.599, Recall: 0.547\n","EPOCH -- 203\n","Iteration: 0. Train Loss: 1.06414. Val Loss: 0.95728, F1: 0.533, ECE: 0.206, Precision: 0.612, Recall: 0.560\n","EPOCH -- 204\n","Iteration: 0. Train Loss: 1.06149. Val Loss: 0.96076, F1: 0.521, ECE: 0.219, Precision: 0.600, Recall: 0.547\n","EPOCH -- 205\n","Iteration: 0. Train Loss: 1.06283. Val Loss: 0.96242, F1: 0.520, ECE: 0.228, Precision: 0.599, Recall: 0.547\n","EPOCH -- 206\n","Iteration: 0. Train Loss: 1.06588. Val Loss: 0.96587, F1: 0.543, ECE: 0.182, Precision: 0.648, Recall: 0.573\n","EPOCH -- 207\n","Iteration: 0. Train Loss: 1.06287. Val Loss: 0.95590, F1: 0.554, ECE: 0.175, Precision: 0.657, Recall: 0.587\n","EPOCH -- 208\n","Iteration: 0. Train Loss: 1.06509. Val Loss: 0.96013, F1: 0.533, ECE: 0.199, Precision: 0.612, Recall: 0.560\n","EPOCH -- 209\n","Iteration: 0. Train Loss: 1.06470. Val Loss: 0.95411, F1: 0.545, ECE: 0.180, Precision: 0.623, Recall: 0.573\n","EPOCH -- 210\n","Iteration: 0. Train Loss: 1.06346. Val Loss: 0.94468, F1: 0.545, ECE: 0.186, Precision: 0.623, Recall: 0.573\n","EPOCH -- 211\n","Iteration: 0. Train Loss: 1.06149. Val Loss: 0.95492, F1: 0.508, ECE: 0.238, Precision: 0.588, Recall: 0.533\n","EPOCH -- 212\n","Iteration: 0. Train Loss: 1.06287. Val Loss: 0.94812, F1: 0.520, ECE: 0.221, Precision: 0.599, Recall: 0.547\n","EPOCH -- 213\n","Iteration: 0. Train Loss: 1.06363. Val Loss: 0.93410, F1: 0.520, ECE: 0.221, Precision: 0.599, Recall: 0.547\n","EPOCH -- 214\n","Iteration: 0. Train Loss: 1.06260. Val Loss: 0.92370, F1: 0.532, ECE: 0.197, Precision: 0.610, Recall: 0.560\n","EPOCH -- 215\n","Iteration: 0. Train Loss: 1.06848. Val Loss: 0.93481, F1: 0.533, ECE: 0.188, Precision: 0.612, Recall: 0.560\n","EPOCH -- 216\n","Iteration: 0. Train Loss: 1.06352. Val Loss: 0.94184, F1: 0.533, ECE: 0.200, Precision: 0.612, Recall: 0.560\n","EPOCH -- 217\n","Iteration: 0. Train Loss: 1.06447. Val Loss: 0.95052, F1: 0.533, ECE: 0.200, Precision: 0.612, Recall: 0.560\n","EPOCH -- 218\n","Iteration: 0. Train Loss: 1.06154. Val Loss: 0.95834, F1: 0.531, ECE: 0.193, Precision: 0.586, Recall: 0.560\n","EPOCH -- 219\n","Iteration: 0. Train Loss: 1.06504. Val Loss: 0.95299, F1: 0.554, ECE: 0.191, Precision: 0.628, Recall: 0.587\n","EPOCH -- 220\n","Iteration: 0. Train Loss: 1.06661. Val Loss: 0.94768, F1: 0.543, ECE: 0.178, Precision: 0.648, Recall: 0.573\n","EPOCH -- 221\n","Iteration: 0. Train Loss: 1.06331. Val Loss: 0.95969, F1: 0.543, ECE: 0.192, Precision: 0.619, Recall: 0.573\n","EPOCH -- 222\n","Iteration: 0. Train Loss: 1.06512. Val Loss: 0.96474, F1: 0.532, ECE: 0.193, Precision: 0.610, Recall: 0.560\n","EPOCH -- 223\n","Iteration: 0. Train Loss: 1.06504. Val Loss: 0.98475, F1: 0.543, ECE: 0.154, Precision: 0.648, Recall: 0.573\n","EPOCH -- 224\n","Iteration: 0. Train Loss: 1.06381. Val Loss: 0.97128, F1: 0.544, ECE: 0.154, Precision: 0.650, Recall: 0.573\n","EPOCH -- 225\n","Iteration: 0. Train Loss: 1.06124. Val Loss: 0.95771, F1: 0.543, ECE: 0.197, Precision: 0.648, Recall: 0.573\n","EPOCH -- 226\n","Iteration: 0. Train Loss: 1.06425. Val Loss: 0.95199, F1: 0.554, ECE: 0.171, Precision: 0.658, Recall: 0.587\n","EPOCH -- 227\n","Iteration: 0. Train Loss: 1.06252. Val Loss: 0.95433, F1: 0.543, ECE: 0.209, Precision: 0.648, Recall: 0.573\n","EPOCH -- 228\n","Iteration: 0. Train Loss: 1.06445. Val Loss: 0.94140, F1: 0.551, ECE: 0.204, Precision: 0.649, Recall: 0.573\n","EPOCH -- 229\n","Iteration: 0. Train Loss: 1.06714. Val Loss: 0.94017, F1: 0.530, ECE: 0.211, Precision: 0.607, Recall: 0.560\n","EPOCH -- 230\n","Iteration: 0. Train Loss: 1.06415. Val Loss: 0.94056, F1: 0.565, ECE: 0.176, Precision: 0.616, Recall: 0.600\n","EPOCH -- 231\n","Iteration: 0. Train Loss: 1.06328. Val Loss: 0.93189, F1: 0.567, ECE: 0.167, Precision: 0.640, Recall: 0.600\n","EPOCH -- 232\n","Iteration: 0. Train Loss: 1.06288. Val Loss: 0.92746, F1: 0.555, ECE: 0.171, Precision: 0.607, Recall: 0.587\n","EPOCH -- 233\n","Iteration: 0. Train Loss: 1.06155. Val Loss: 0.93164, F1: 0.567, ECE: 0.149, Precision: 0.670, Recall: 0.600\n","EPOCH -- 234\n","Iteration: 0. Train Loss: 1.06069. Val Loss: 0.93225, F1: 0.544, ECE: 0.192, Precision: 0.621, Recall: 0.573\n","EPOCH -- 235\n","Iteration: 0. Train Loss: 1.06360. Val Loss: 0.94547, F1: 0.543, ECE: 0.195, Precision: 0.648, Recall: 0.573\n","EPOCH -- 236\n","Iteration: 0. Train Loss: 1.06221. Val Loss: 0.94098, F1: 0.554, ECE: 0.194, Precision: 0.657, Recall: 0.587\n","EPOCH -- 237\n","Iteration: 0. Train Loss: 1.06380. Val Loss: 0.93409, F1: 0.554, ECE: 0.185, Precision: 0.628, Recall: 0.587\n","EPOCH -- 238\n","Iteration: 0. Train Loss: 1.06525. Val Loss: 0.93436, F1: 0.554, ECE: 0.173, Precision: 0.628, Recall: 0.587\n","EPOCH -- 239\n","Iteration: 0. Train Loss: 1.06043. Val Loss: 0.93691, F1: 0.554, ECE: 0.172, Precision: 0.628, Recall: 0.587\n","EPOCH -- 240\n","Iteration: 0. Train Loss: 1.06204. Val Loss: 0.94629, F1: 0.553, ECE: 0.179, Precision: 0.627, Recall: 0.587\n","EPOCH -- 241\n","Iteration: 0. Train Loss: 1.06242. Val Loss: 0.94760, F1: 0.554, ECE: 0.187, Precision: 0.628, Recall: 0.587\n","EPOCH -- 242\n","Iteration: 0. Train Loss: 1.06085. Val Loss: 0.94949, F1: 0.554, ECE: 0.194, Precision: 0.628, Recall: 0.587\n","EPOCH -- 243\n","Iteration: 0. Train Loss: 1.06144. Val Loss: 0.94284, F1: 0.554, ECE: 0.172, Precision: 0.628, Recall: 0.587\n","EPOCH -- 244\n","Iteration: 0. Train Loss: 1.06023. Val Loss: 0.95007, F1: 0.573, ECE: 0.158, Precision: 0.642, Recall: 0.600\n","EPOCH -- 245\n","Iteration: 0. Train Loss: 1.06471. Val Loss: 0.94588, F1: 0.586, ECE: 0.167, Precision: 0.653, Recall: 0.613\n","EPOCH -- 246\n","Iteration: 0. Train Loss: 1.06326. Val Loss: 0.94717, F1: 0.575, ECE: 0.184, Precision: 0.645, Recall: 0.600\n","EPOCH -- 247\n","Iteration: 0. Train Loss: 1.06076. Val Loss: 0.93801, F1: 0.564, ECE: 0.183, Precision: 0.637, Recall: 0.587\n","EPOCH -- 248\n","Iteration: 0. Train Loss: 1.06354. Val Loss: 0.93728, F1: 0.554, ECE: 0.185, Precision: 0.628, Recall: 0.587\n","EPOCH -- 249\n","Iteration: 0. Train Loss: 1.06424. Val Loss: 0.94672, F1: 0.532, ECE: 0.221, Precision: 0.609, Recall: 0.560\n","EPOCH -- 250\n","Iteration: 0. Train Loss: 1.06123. Val Loss: 0.95722, F1: 0.532, ECE: 0.211, Precision: 0.610, Recall: 0.560\n","EPOCH -- 251\n","Iteration: 0. Train Loss: 1.06089. Val Loss: 0.96989, F1: 0.532, ECE: 0.187, Precision: 0.640, Recall: 0.560\n","EPOCH -- 252\n","Iteration: 0. Train Loss: 1.06516. Val Loss: 0.96439, F1: 0.533, ECE: 0.215, Precision: 0.641, Recall: 0.560\n","EPOCH -- 253\n","Iteration: 0. Train Loss: 1.06230. Val Loss: 0.95941, F1: 0.554, ECE: 0.153, Precision: 0.658, Recall: 0.587\n","EPOCH -- 254\n","Iteration: 0. Train Loss: 1.06164. Val Loss: 0.93866, F1: 0.554, ECE: 0.197, Precision: 0.628, Recall: 0.587\n","EPOCH -- 255\n","Iteration: 0. Train Loss: 1.06297. Val Loss: 0.93461, F1: 0.554, ECE: 0.191, Precision: 0.628, Recall: 0.587\n","EPOCH -- 256\n","Iteration: 0. Train Loss: 1.06190. Val Loss: 0.94348, F1: 0.544, ECE: 0.207, Precision: 0.621, Recall: 0.573\n","EPOCH -- 257\n","Iteration: 0. Train Loss: 1.06220. Val Loss: 0.96970, F1: 0.532, ECE: 0.198, Precision: 0.610, Recall: 0.560\n","EPOCH -- 258\n","Iteration: 0. Train Loss: 1.06173. Val Loss: 0.98010, F1: 0.564, ECE: 0.150, Precision: 0.667, Recall: 0.600\n","EPOCH -- 259\n","Iteration: 0. Train Loss: 1.06248. Val Loss: 0.97629, F1: 0.564, ECE: 0.174, Precision: 0.667, Recall: 0.600\n","EPOCH -- 260\n","Iteration: 0. Train Loss: 1.07005. Val Loss: 0.95457, F1: 0.565, ECE: 0.154, Precision: 0.667, Recall: 0.600\n","EPOCH -- 261\n","Iteration: 0. Train Loss: 1.06252. Val Loss: 0.92726, F1: 0.556, ECE: 0.176, Precision: 0.632, Recall: 0.587\n","EPOCH -- 262\n","Iteration: 0. Train Loss: 1.06175. Val Loss: 0.92515, F1: 0.544, ECE: 0.192, Precision: 0.621, Recall: 0.573\n","EPOCH -- 263\n","Iteration: 0. Train Loss: 1.06103. Val Loss: 0.93406, F1: 0.554, ECE: 0.155, Precision: 0.628, Recall: 0.587\n","EPOCH -- 264\n","Iteration: 0. Train Loss: 1.06194. Val Loss: 0.95679, F1: 0.553, ECE: 0.156, Precision: 0.627, Recall: 0.587\n","EPOCH -- 265\n","Iteration: 0. Train Loss: 1.06237. Val Loss: 0.95655, F1: 0.553, ECE: 0.146, Precision: 0.657, Recall: 0.587\n","EPOCH -- 266\n","Iteration: 0. Train Loss: 1.06102. Val Loss: 0.94360, F1: 0.554, ECE: 0.135, Precision: 0.657, Recall: 0.587\n","EPOCH -- 267\n","Iteration: 0. Train Loss: 1.06622. Val Loss: 0.93059, F1: 0.566, ECE: 0.144, Precision: 0.639, Recall: 0.600\n","EPOCH -- 268\n","Iteration: 0. Train Loss: 1.06105. Val Loss: 0.93642, F1: 0.555, ECE: 0.146, Precision: 0.630, Recall: 0.587\n","EPOCH -- 269\n","Iteration: 0. Train Loss: 1.06577. Val Loss: 0.94591, F1: 0.532, ECE: 0.175, Precision: 0.609, Recall: 0.560\n","EPOCH -- 270\n","Iteration: 0. Train Loss: 1.06065. Val Loss: 0.93918, F1: 0.545, ECE: 0.148, Precision: 0.652, Recall: 0.573\n","EPOCH -- 271\n","Iteration: 0. Train Loss: 1.06290. Val Loss: 0.94748, F1: 0.543, ECE: 0.152, Precision: 0.648, Recall: 0.573\n","EPOCH -- 272\n","Iteration: 0. Train Loss: 1.06079. Val Loss: 0.93935, F1: 0.544, ECE: 0.164, Precision: 0.650, Recall: 0.573\n","EPOCH -- 273\n","Iteration: 0. Train Loss: 1.06289. Val Loss: 0.93576, F1: 0.556, ECE: 0.177, Precision: 0.632, Recall: 0.587\n","EPOCH -- 274\n","Iteration: 0. Train Loss: 1.06179. Val Loss: 0.94815, F1: 0.563, ECE: 0.157, Precision: 0.633, Recall: 0.587\n","EPOCH -- 275\n","Iteration: 0. Train Loss: 1.06407. Val Loss: 0.95233, F1: 0.563, ECE: 0.159, Precision: 0.633, Recall: 0.587\n","EPOCH -- 276\n","Iteration: 0. Train Loss: 1.06141. Val Loss: 0.94739, F1: 0.555, ECE: 0.151, Precision: 0.629, Recall: 0.587\n","EPOCH -- 277\n","Iteration: 0. Train Loss: 1.06030. Val Loss: 0.94536, F1: 0.554, ECE: 0.142, Precision: 0.628, Recall: 0.587\n","EPOCH -- 278\n","Iteration: 0. Train Loss: 1.06228. Val Loss: 0.95190, F1: 0.543, ECE: 0.160, Precision: 0.619, Recall: 0.573\n","EPOCH -- 279\n","Iteration: 0. Train Loss: 1.06278. Val Loss: 0.96202, F1: 0.543, ECE: 0.186, Precision: 0.619, Recall: 0.573\n","EPOCH -- 280\n","Iteration: 0. Train Loss: 1.06388. Val Loss: 0.95819, F1: 0.555, ECE: 0.166, Precision: 0.630, Recall: 0.587\n","EPOCH -- 281\n","Iteration: 0. Train Loss: 1.06080. Val Loss: 0.96709, F1: 0.556, ECE: 0.165, Precision: 0.661, Recall: 0.587\n","EPOCH -- 282\n","Iteration: 0. Train Loss: 1.06219. Val Loss: 0.97036, F1: 0.556, ECE: 0.152, Precision: 0.661, Recall: 0.587\n","EPOCH -- 283\n","Iteration: 0. Train Loss: 1.06174. Val Loss: 0.96239, F1: 0.532, ECE: 0.213, Precision: 0.639, Recall: 0.560\n","EPOCH -- 284\n","Iteration: 0. Train Loss: 1.06327. Val Loss: 0.94534, F1: 0.555, ECE: 0.180, Precision: 0.607, Recall: 0.587\n","EPOCH -- 285\n","Iteration: 0. Train Loss: 1.06412. Val Loss: 0.96088, F1: 0.543, ECE: 0.190, Precision: 0.619, Recall: 0.573\n","EPOCH -- 286\n","Iteration: 0. Train Loss: 1.06381. Val Loss: 0.95288, F1: 0.554, ECE: 0.157, Precision: 0.628, Recall: 0.587\n","EPOCH -- 287\n","Iteration: 0. Train Loss: 1.06269. Val Loss: 0.96737, F1: 0.542, ECE: 0.172, Precision: 0.618, Recall: 0.573\n","EPOCH -- 288\n","Iteration: 0. Train Loss: 1.06172. Val Loss: 0.97781, F1: 0.542, ECE: 0.167, Precision: 0.618, Recall: 0.573\n","EPOCH -- 289\n","Iteration: 0. Train Loss: 1.06643. Val Loss: 0.95920, F1: 0.554, ECE: 0.157, Precision: 0.657, Recall: 0.587\n","EPOCH -- 290\n","Iteration: 0. Train Loss: 1.06256. Val Loss: 0.95460, F1: 0.543, ECE: 0.189, Precision: 0.618, Recall: 0.573\n","EPOCH -- 291\n","Iteration: 0. Train Loss: 1.06244. Val Loss: 0.93366, F1: 0.554, ECE: 0.189, Precision: 0.628, Recall: 0.587\n","EPOCH -- 292\n","Iteration: 0. Train Loss: 1.06144. Val Loss: 0.93907, F1: 0.566, ECE: 0.182, Precision: 0.668, Recall: 0.600\n","EPOCH -- 293\n","Iteration: 0. Train Loss: 1.06416. Val Loss: 0.94676, F1: 0.543, ECE: 0.216, Precision: 0.618, Recall: 0.573\n","EPOCH -- 294\n","Iteration: 0. Train Loss: 1.06267. Val Loss: 0.93696, F1: 0.554, ECE: 0.200, Precision: 0.628, Recall: 0.587\n","EPOCH -- 295\n","Iteration: 0. Train Loss: 1.06050. Val Loss: 0.93761, F1: 0.566, ECE: 0.194, Precision: 0.669, Recall: 0.600\n","EPOCH -- 296\n","Iteration: 0. Train Loss: 1.06104. Val Loss: 0.93149, F1: 0.554, ECE: 0.175, Precision: 0.658, Recall: 0.587\n","EPOCH -- 297\n","Iteration: 0. Train Loss: 1.06083. Val Loss: 0.91949, F1: 0.557, ECE: 0.183, Precision: 0.635, Recall: 0.587\n","EPOCH -- 298\n","Iteration: 0. Train Loss: 1.06317. Val Loss: 0.92397, F1: 0.566, ECE: 0.171, Precision: 0.639, Recall: 0.600\n","EPOCH -- 299\n","Iteration: 0. Train Loss: 1.06114. Val Loss: 0.92217, F1: 0.532, ECE: 0.224, Precision: 0.610, Recall: 0.560\n","EPOCH -- 300\n","Iteration: 0. Train Loss: 1.06086. Val Loss: 0.96616, F1: 0.532, ECE: 0.235, Precision: 0.609, Recall: 0.560\n","EPOCH -- 301\n","Iteration: 0. Train Loss: 1.06346. Val Loss: 0.95973, F1: 0.557, ECE: 0.189, Precision: 0.611, Recall: 0.587\n","EPOCH -- 302\n","Iteration: 0. Train Loss: 1.06092. Val Loss: 0.95337, F1: 0.545, ECE: 0.170, Precision: 0.623, Recall: 0.573\n","EPOCH -- 303\n","Iteration: 0. Train Loss: 1.06158. Val Loss: 0.94808, F1: 0.535, ECE: 0.204, Precision: 0.618, Recall: 0.560\n","EPOCH -- 304\n","Iteration: 0. Train Loss: 1.06108. Val Loss: 0.94021, F1: 0.546, ECE: 0.196, Precision: 0.655, Recall: 0.573\n","EPOCH -- 305\n","Iteration: 0. Train Loss: 1.06170. Val Loss: 0.95073, F1: 0.556, ECE: 0.173, Precision: 0.663, Recall: 0.587\n","EPOCH -- 306\n","Iteration: 0. Train Loss: 1.06268. Val Loss: 0.95970, F1: 0.566, ECE: 0.162, Precision: 0.639, Recall: 0.600\n","EPOCH -- 307\n","Iteration: 0. Train Loss: 1.06385. Val Loss: 0.95978, F1: 0.566, ECE: 0.166, Precision: 0.639, Recall: 0.600\n","EPOCH -- 308\n","Iteration: 0. Train Loss: 1.06080. Val Loss: 0.95004, F1: 0.555, ECE: 0.174, Precision: 0.661, Recall: 0.587\n","EPOCH -- 309\n","Iteration: 0. Train Loss: 1.06062. Val Loss: 0.94848, F1: 0.556, ECE: 0.185, Precision: 0.663, Recall: 0.587\n","EPOCH -- 310\n","Iteration: 0. Train Loss: 1.06485. Val Loss: 0.95631, F1: 0.545, ECE: 0.188, Precision: 0.600, Recall: 0.573\n","EPOCH -- 311\n","Iteration: 0. Train Loss: 1.06340. Val Loss: 0.96590, F1: 0.545, ECE: 0.177, Precision: 0.600, Recall: 0.573\n","EPOCH -- 312\n","Iteration: 0. Train Loss: 1.06525. Val Loss: 0.97255, F1: 0.556, ECE: 0.154, Precision: 0.661, Recall: 0.587\n","EPOCH -- 313\n","Iteration: 0. Train Loss: 1.06188. Val Loss: 0.96211, F1: 0.567, ECE: 0.167, Precision: 0.670, Recall: 0.600\n","EPOCH -- 314\n","Iteration: 0. Train Loss: 1.06167. Val Loss: 0.94994, F1: 0.555, ECE: 0.196, Precision: 0.661, Recall: 0.587\n","EPOCH -- 315\n","Iteration: 0. Train Loss: 1.06136. Val Loss: 0.94116, F1: 0.544, ECE: 0.204, Precision: 0.652, Recall: 0.573\n","EPOCH -- 316\n","Iteration: 0. Train Loss: 1.06221. Val Loss: 0.94286, F1: 0.533, ECE: 0.219, Precision: 0.591, Recall: 0.560\n","EPOCH -- 317\n","Iteration: 0. Train Loss: 1.06341. Val Loss: 0.94713, F1: 0.534, ECE: 0.225, Precision: 0.615, Recall: 0.560\n","EPOCH -- 318\n","Iteration: 0. Train Loss: 1.06193. Val Loss: 0.95895, F1: 0.532, ECE: 0.230, Precision: 0.610, Recall: 0.560\n","EPOCH -- 319\n","Iteration: 0. Train Loss: 1.06208. Val Loss: 0.96382, F1: 0.532, ECE: 0.239, Precision: 0.587, Recall: 0.560\n","EPOCH -- 320\n","Iteration: 0. Train Loss: 1.06223. Val Loss: 0.94467, F1: 0.532, ECE: 0.227, Precision: 0.610, Recall: 0.560\n","EPOCH -- 321\n","Iteration: 0. Train Loss: 1.06311. Val Loss: 0.94354, F1: 0.543, ECE: 0.208, Precision: 0.619, Recall: 0.573\n","EPOCH -- 322\n","Iteration: 0. Train Loss: 1.06244. Val Loss: 0.94014, F1: 0.544, ECE: 0.203, Precision: 0.621, Recall: 0.573\n","EPOCH -- 323\n","Iteration: 0. Train Loss: 1.06153. Val Loss: 0.94870, F1: 0.533, ECE: 0.222, Precision: 0.589, Recall: 0.560\n","EPOCH -- 324\n","Iteration: 0. Train Loss: 1.06531. Val Loss: 0.94796, F1: 0.544, ECE: 0.207, Precision: 0.650, Recall: 0.573\n","EPOCH -- 325\n","Iteration: 0. Train Loss: 1.06041. Val Loss: 0.95704, F1: 0.554, ECE: 0.206, Precision: 0.628, Recall: 0.587\n","EPOCH -- 326\n","Iteration: 0. Train Loss: 1.06441. Val Loss: 0.95227, F1: 0.544, ECE: 0.211, Precision: 0.650, Recall: 0.573\n","EPOCH -- 327\n","Iteration: 0. Train Loss: 1.06407. Val Loss: 0.94236, F1: 0.556, ECE: 0.185, Precision: 0.702, Recall: 0.587\n","EPOCH -- 328\n","Iteration: 0. Train Loss: 1.06170. Val Loss: 0.94279, F1: 0.544, ECE: 0.183, Precision: 0.650, Recall: 0.573\n","EPOCH -- 329\n","Iteration: 0. Train Loss: 1.06100. Val Loss: 0.94903, F1: 0.544, ECE: 0.189, Precision: 0.621, Recall: 0.573\n","EPOCH -- 330\n","Iteration: 0. Train Loss: 1.06078. Val Loss: 0.96419, F1: 0.555, ECE: 0.174, Precision: 0.659, Recall: 0.587\n","EPOCH -- 331\n","Iteration: 0. Train Loss: 1.05956. Val Loss: 0.96533, F1: 0.544, ECE: 0.216, Precision: 0.650, Recall: 0.573\n","EPOCH -- 332\n","Iteration: 0. Train Loss: 1.06135. Val Loss: 0.96822, F1: 0.543, ECE: 0.193, Precision: 0.619, Recall: 0.573\n","EPOCH -- 333\n","Iteration: 0. Train Loss: 1.06193. Val Loss: 0.96224, F1: 0.544, ECE: 0.190, Precision: 0.598, Recall: 0.573\n","EPOCH -- 334\n","Iteration: 0. Train Loss: 1.06157. Val Loss: 0.95507, F1: 0.544, ECE: 0.218, Precision: 0.598, Recall: 0.573\n","EPOCH -- 335\n","Iteration: 0. Train Loss: 1.06049. Val Loss: 0.94935, F1: 0.544, ECE: 0.210, Precision: 0.621, Recall: 0.573\n","EPOCH -- 336\n","Iteration: 0. Train Loss: 1.06174. Val Loss: 0.96020, F1: 0.543, ECE: 0.211, Precision: 0.619, Recall: 0.573\n","EPOCH -- 337\n","Iteration: 0. Train Loss: 1.06251. Val Loss: 0.94187, F1: 0.545, ECE: 0.210, Precision: 0.600, Recall: 0.573\n","EPOCH -- 338\n","Iteration: 0. Train Loss: 1.06108. Val Loss: 0.94735, F1: 0.545, ECE: 0.214, Precision: 0.600, Recall: 0.573\n","EPOCH -- 339\n","Iteration: 0. Train Loss: 1.06241. Val Loss: 0.95094, F1: 0.545, ECE: 0.213, Precision: 0.600, Recall: 0.573\n","EPOCH -- 340\n","Iteration: 0. Train Loss: 1.06075. Val Loss: 0.93836, F1: 0.544, ECE: 0.210, Precision: 0.621, Recall: 0.573\n","EPOCH -- 341\n","Iteration: 0. Train Loss: 1.06083. Val Loss: 0.92801, F1: 0.579, ECE: 0.182, Precision: 0.723, Recall: 0.613\n","EPOCH -- 342\n","Iteration: 0. Train Loss: 1.05949. Val Loss: 0.92651, F1: 0.567, ECE: 0.184, Precision: 0.713, Recall: 0.600\n","EPOCH -- 343\n","Iteration: 0. Train Loss: 1.06219. Val Loss: 0.93892, F1: 0.555, ECE: 0.197, Precision: 0.630, Recall: 0.587\n","EPOCH -- 344\n","Iteration: 0. Train Loss: 1.06379. Val Loss: 0.92169, F1: 0.566, ECE: 0.181, Precision: 0.668, Recall: 0.600\n","EPOCH -- 345\n","Iteration: 0. Train Loss: 1.06817. Val Loss: 0.93018, F1: 0.566, ECE: 0.174, Precision: 0.669, Recall: 0.600\n","EPOCH -- 346\n","Iteration: 0. Train Loss: 1.06831. Val Loss: 0.90582, F1: 0.589, ECE: 0.134, Precision: 0.730, Recall: 0.627\n","EPOCH -- 347\n","Iteration: 0. Train Loss: 1.06388. Val Loss: 0.92595, F1: 0.577, ECE: 0.134, Precision: 0.720, Recall: 0.613\n","EPOCH -- 348\n","Iteration: 0. Train Loss: 1.06108. Val Loss: 0.91856, F1: 0.554, ECE: 0.161, Precision: 0.658, Recall: 0.587\n","EPOCH -- 349\n","Iteration: 0. Train Loss: 1.06108. Val Loss: 0.93016, F1: 0.554, ECE: 0.166, Precision: 0.658, Recall: 0.587\n","EPOCH -- 350\n","Iteration: 0. Train Loss: 1.06586. Val Loss: 0.92723, F1: 0.554, ECE: 0.148, Precision: 0.658, Recall: 0.587\n","EPOCH -- 351\n","Iteration: 0. Train Loss: 1.06108. Val Loss: 0.94216, F1: 0.565, ECE: 0.160, Precision: 0.668, Recall: 0.600\n","EPOCH -- 352\n","Iteration: 0. Train Loss: 1.06124. Val Loss: 0.95325, F1: 0.565, ECE: 0.165, Precision: 0.668, Recall: 0.600\n","EPOCH -- 353\n","Iteration: 0. Train Loss: 1.06367. Val Loss: 0.93421, F1: 0.565, ECE: 0.160, Precision: 0.710, Recall: 0.600\n","EPOCH -- 354\n","Iteration: 0. Train Loss: 1.06104. Val Loss: 0.92689, F1: 0.556, ECE: 0.166, Precision: 0.702, Recall: 0.587\n","EPOCH -- 355\n","Iteration: 0. Train Loss: 1.06069. Val Loss: 0.92461, F1: 0.556, ECE: 0.166, Precision: 0.704, Recall: 0.587\n","EPOCH -- 356\n","Iteration: 0. Train Loss: 1.06230. Val Loss: 0.92067, F1: 0.543, ECE: 0.180, Precision: 0.649, Recall: 0.573\n","EPOCH -- 357\n","Iteration: 0. Train Loss: 1.06374. Val Loss: 0.93485, F1: 0.554, ECE: 0.170, Precision: 0.658, Recall: 0.587\n","EPOCH -- 358\n","Iteration: 0. Train Loss: 1.06335. Val Loss: 0.93853, F1: 0.544, ECE: 0.187, Precision: 0.692, Recall: 0.573\n","EPOCH -- 359\n","Iteration: 0. Train Loss: 1.06425. Val Loss: 0.93668, F1: 0.555, ECE: 0.179, Precision: 0.659, Recall: 0.587\n","EPOCH -- 360\n","Iteration: 0. Train Loss: 1.06745. Val Loss: 0.95949, F1: 0.555, ECE: 0.173, Precision: 0.630, Recall: 0.587\n","EPOCH -- 361\n","Iteration: 0. Train Loss: 1.06235. Val Loss: 0.95490, F1: 0.555, ECE: 0.181, Precision: 0.659, Recall: 0.587\n","EPOCH -- 362\n","Iteration: 0. Train Loss: 1.06305. Val Loss: 0.94205, F1: 0.555, ECE: 0.191, Precision: 0.659, Recall: 0.587\n","EPOCH -- 363\n","Iteration: 0. Train Loss: 1.06242. Val Loss: 0.93719, F1: 0.555, ECE: 0.197, Precision: 0.659, Recall: 0.587\n","EPOCH -- 364\n","Iteration: 0. Train Loss: 1.06037. Val Loss: 0.92842, F1: 0.566, ECE: 0.170, Precision: 0.711, Recall: 0.600\n","EPOCH -- 365\n","Iteration: 0. Train Loss: 1.06452. Val Loss: 0.93476, F1: 0.554, ECE: 0.185, Precision: 0.658, Recall: 0.587\n","EPOCH -- 366\n","Iteration: 0. Train Loss: 1.06247. Val Loss: 0.94941, F1: 0.554, ECE: 0.170, Precision: 0.658, Recall: 0.587\n","EPOCH -- 367\n","Iteration: 0. Train Loss: 1.06863. Val Loss: 0.96105, F1: 0.554, ECE: 0.160, Precision: 0.658, Recall: 0.587\n","EPOCH -- 368\n","Iteration: 0. Train Loss: 1.06303. Val Loss: 0.95345, F1: 0.554, ECE: 0.164, Precision: 0.658, Recall: 0.587\n","EPOCH -- 369\n","Iteration: 0. Train Loss: 1.06115. Val Loss: 0.95733, F1: 0.566, ECE: 0.149, Precision: 0.710, Recall: 0.600\n","EPOCH -- 370\n","Iteration: 0. Train Loss: 1.06496. Val Loss: 0.95335, F1: 0.566, ECE: 0.167, Precision: 0.710, Recall: 0.600\n","EPOCH -- 371\n","Iteration: 0. Train Loss: 1.06180. Val Loss: 0.94946, F1: 0.566, ECE: 0.192, Precision: 0.710, Recall: 0.600\n","EPOCH -- 372\n","Iteration: 0. Train Loss: 1.06376. Val Loss: 0.94789, F1: 0.554, ECE: 0.202, Precision: 0.658, Recall: 0.587\n","EPOCH -- 373\n","Iteration: 0. Train Loss: 1.06235. Val Loss: 0.95366, F1: 0.555, ECE: 0.183, Precision: 0.659, Recall: 0.587\n","EPOCH -- 374\n","Iteration: 0. Train Loss: 1.06310. Val Loss: 0.96394, F1: 0.555, ECE: 0.183, Precision: 0.659, Recall: 0.587\n","EPOCH -- 375\n","Iteration: 0. Train Loss: 1.06342. Val Loss: 0.96989, F1: 0.555, ECE: 0.190, Precision: 0.659, Recall: 0.587\n","EPOCH -- 376\n","Iteration: 0. Train Loss: 1.06164. Val Loss: 0.96577, F1: 0.554, ECE: 0.185, Precision: 0.658, Recall: 0.587\n","EPOCH -- 377\n","Iteration: 0. Train Loss: 1.06237. Val Loss: 0.95071, F1: 0.554, ECE: 0.185, Precision: 0.658, Recall: 0.587\n","EPOCH -- 378\n","Iteration: 0. Train Loss: 1.06012. Val Loss: 0.95739, F1: 0.555, ECE: 0.206, Precision: 0.659, Recall: 0.587\n","EPOCH -- 379\n","Iteration: 0. Train Loss: 1.06208. Val Loss: 0.96220, F1: 0.555, ECE: 0.161, Precision: 0.659, Recall: 0.587\n","EPOCH -- 380\n","Iteration: 0. Train Loss: 1.06070. Val Loss: 0.95883, F1: 0.555, ECE: 0.162, Precision: 0.659, Recall: 0.587\n","EPOCH -- 381\n","Iteration: 0. Train Loss: 1.06199. Val Loss: 0.96486, F1: 0.554, ECE: 0.152, Precision: 0.658, Recall: 0.587\n","EPOCH -- 382\n","Iteration: 0. Train Loss: 1.06186. Val Loss: 0.96100, F1: 0.565, ECE: 0.142, Precision: 0.668, Recall: 0.600\n","EPOCH -- 383\n","Iteration: 0. Train Loss: 1.06069. Val Loss: 0.94800, F1: 0.577, ECE: 0.141, Precision: 0.678, Recall: 0.613\n","EPOCH -- 384\n","Iteration: 0. Train Loss: 1.06177. Val Loss: 0.94559, F1: 0.577, ECE: 0.157, Precision: 0.679, Recall: 0.613\n","EPOCH -- 385\n","Iteration: 0. Train Loss: 1.06148. Val Loss: 0.94741, F1: 0.567, ECE: 0.196, Precision: 0.670, Recall: 0.600\n","EPOCH -- 386\n","Iteration: 0. Train Loss: 1.06146. Val Loss: 0.95490, F1: 0.566, ECE: 0.187, Precision: 0.669, Recall: 0.600\n","EPOCH -- 387\n","Iteration: 0. Train Loss: 1.06143. Val Loss: 0.94940, F1: 0.567, ECE: 0.151, Precision: 0.711, Recall: 0.600\n","EPOCH -- 388\n","Iteration: 0. Train Loss: 1.06184. Val Loss: 0.95429, F1: 0.566, ECE: 0.144, Precision: 0.669, Recall: 0.600\n","EPOCH -- 389\n","Iteration: 0. Train Loss: 1.06066. Val Loss: 0.95969, F1: 0.555, ECE: 0.157, Precision: 0.701, Recall: 0.587\n","EPOCH -- 390\n","Iteration: 0. Train Loss: 1.06123. Val Loss: 0.95446, F1: 0.566, ECE: 0.154, Precision: 0.668, Recall: 0.600\n","EPOCH -- 391\n","Iteration: 0. Train Loss: 1.06085. Val Loss: 0.95501, F1: 0.577, ECE: 0.124, Precision: 0.679, Recall: 0.613\n","EPOCH -- 392\n","Iteration: 0. Train Loss: 1.06332. Val Loss: 0.94101, F1: 0.578, ECE: 0.169, Precision: 0.721, Recall: 0.613\n","EPOCH -- 393\n","Iteration: 0. Train Loss: 1.06145. Val Loss: 0.93975, F1: 0.577, ECE: 0.166, Precision: 0.679, Recall: 0.613\n","EPOCH -- 394\n","Iteration: 0. Train Loss: 1.06587. Val Loss: 0.93506, F1: 0.578, ECE: 0.172, Precision: 0.721, Recall: 0.613\n","EPOCH -- 395\n","Iteration: 0. Train Loss: 1.06045. Val Loss: 0.94242, F1: 0.566, ECE: 0.163, Precision: 0.668, Recall: 0.600\n","EPOCH -- 396\n","Iteration: 0. Train Loss: 1.06132. Val Loss: 0.94144, F1: 0.566, ECE: 0.147, Precision: 0.668, Recall: 0.600\n","EPOCH -- 397\n","Iteration: 0. Train Loss: 1.06099. Val Loss: 0.94508, F1: 0.577, ECE: 0.132, Precision: 0.719, Recall: 0.613\n","EPOCH -- 398\n","Iteration: 0. Train Loss: 1.06106. Val Loss: 0.94349, F1: 0.578, ECE: 0.135, Precision: 0.720, Recall: 0.613\n","EPOCH -- 399\n","Iteration: 0. Train Loss: 1.06149. Val Loss: 0.93177, F1: 0.567, ECE: 0.162, Precision: 0.712, Recall: 0.600\n","EPOCH -- 400\n","Iteration: 0. Train Loss: 1.07078. Val Loss: 0.93325, F1: 0.577, ECE: 0.147, Precision: 0.719, Recall: 0.613\n","EPOCH -- 401\n","Iteration: 0. Train Loss: 1.06342. Val Loss: 0.93898, F1: 0.577, ECE: 0.139, Precision: 0.678, Recall: 0.613\n","EPOCH -- 402\n","Iteration: 0. Train Loss: 1.06240. Val Loss: 0.92860, F1: 0.578, ECE: 0.133, Precision: 0.680, Recall: 0.613\n","EPOCH -- 403\n","Iteration: 0. Train Loss: 1.05978. Val Loss: 0.91843, F1: 0.578, ECE: 0.137, Precision: 0.680, Recall: 0.613\n","EPOCH -- 404\n","Iteration: 0. Train Loss: 1.06227. Val Loss: 0.92718, F1: 0.578, ECE: 0.117, Precision: 0.680, Recall: 0.613\n","EPOCH -- 405\n","Iteration: 0. Train Loss: 1.06533. Val Loss: 0.92945, F1: 0.566, ECE: 0.136, Precision: 0.669, Recall: 0.600\n","EPOCH -- 406\n","Iteration: 0. Train Loss: 1.06313. Val Loss: 0.93016, F1: 0.578, ECE: 0.134, Precision: 0.680, Recall: 0.613\n","EPOCH -- 407\n","Iteration: 0. Train Loss: 1.06267. Val Loss: 0.93560, F1: 0.554, ECE: 0.162, Precision: 0.658, Recall: 0.587\n","EPOCH -- 408\n","Iteration: 0. Train Loss: 1.06326. Val Loss: 0.93214, F1: 0.567, ECE: 0.158, Precision: 0.641, Recall: 0.600\n","EPOCH -- 409\n","Iteration: 0. Train Loss: 1.06245. Val Loss: 0.92520, F1: 0.579, ECE: 0.115, Precision: 0.683, Recall: 0.613\n","EPOCH -- 410\n","Iteration: 0. Train Loss: 1.06220. Val Loss: 0.92795, F1: 0.579, ECE: 0.111, Precision: 0.683, Recall: 0.613\n","EPOCH -- 411\n","Iteration: 0. Train Loss: 1.06365. Val Loss: 0.93905, F1: 0.590, ECE: 0.116, Precision: 0.692, Recall: 0.627\n","EPOCH -- 412\n","Iteration: 0. Train Loss: 1.06463. Val Loss: 0.93767, F1: 0.566, ECE: 0.158, Precision: 0.668, Recall: 0.600\n","EPOCH -- 413\n","Iteration: 0. Train Loss: 1.06225. Val Loss: 0.93468, F1: 0.590, ECE: 0.123, Precision: 0.692, Recall: 0.627\n","EPOCH -- 414\n","Iteration: 0. Train Loss: 1.06059. Val Loss: 0.93317, F1: 0.567, ECE: 0.154, Precision: 0.670, Recall: 0.600\n","EPOCH -- 415\n","Iteration: 0. Train Loss: 1.06898. Val Loss: 0.92873, F1: 0.590, ECE: 0.112, Precision: 0.732, Recall: 0.627\n","EPOCH -- 416\n","Iteration: 0. Train Loss: 1.06233. Val Loss: 0.94575, F1: 0.580, ECE: 0.131, Precision: 0.726, Recall: 0.613\n","EPOCH -- 417\n","Iteration: 0. Train Loss: 1.06347. Val Loss: 0.95775, F1: 0.567, ECE: 0.144, Precision: 0.670, Recall: 0.600\n","EPOCH -- 418\n","Iteration: 0. Train Loss: 1.06222. Val Loss: 0.95706, F1: 0.567, ECE: 0.155, Precision: 0.672, Recall: 0.600\n","EPOCH -- 419\n","Iteration: 0. Train Loss: 1.06305. Val Loss: 0.94683, F1: 0.567, ECE: 0.142, Precision: 0.670, Recall: 0.600\n","EPOCH -- 420\n","Iteration: 0. Train Loss: 1.06421. Val Loss: 0.95542, F1: 0.567, ECE: 0.144, Precision: 0.713, Recall: 0.600\n","EPOCH -- 421\n","Iteration: 0. Train Loss: 1.06086. Val Loss: 0.96227, F1: 0.567, ECE: 0.151, Precision: 0.670, Recall: 0.600\n","EPOCH -- 422\n","Iteration: 0. Train Loss: 1.06354. Val Loss: 0.95646, F1: 0.567, ECE: 0.162, Precision: 0.670, Recall: 0.600\n","EPOCH -- 423\n","Iteration: 0. Train Loss: 1.06294. Val Loss: 0.95804, F1: 0.567, ECE: 0.159, Precision: 0.672, Recall: 0.600\n","EPOCH -- 424\n","Iteration: 0. Train Loss: 1.06195. Val Loss: 0.95667, F1: 0.567, ECE: 0.160, Precision: 0.672, Recall: 0.600\n","EPOCH -- 425\n","Iteration: 0. Train Loss: 1.06443. Val Loss: 0.95244, F1: 0.578, ECE: 0.129, Precision: 0.680, Recall: 0.613\n","EPOCH -- 426\n","Iteration: 0. Train Loss: 1.06344. Val Loss: 0.94372, F1: 0.578, ECE: 0.135, Precision: 0.680, Recall: 0.613\n","EPOCH -- 427\n","Iteration: 0. Train Loss: 1.06340. Val Loss: 0.94272, F1: 0.566, ECE: 0.140, Precision: 0.668, Recall: 0.600\n","EPOCH -- 428\n","Iteration: 0. Train Loss: 1.06117. Val Loss: 0.92742, F1: 0.578, ECE: 0.166, Precision: 0.680, Recall: 0.613\n","EPOCH -- 429\n","Iteration: 0. Train Loss: 1.06173. Val Loss: 0.92819, F1: 0.577, ECE: 0.153, Precision: 0.679, Recall: 0.613\n","EPOCH -- 430\n","Iteration: 0. Train Loss: 1.06215. Val Loss: 0.94218, F1: 0.577, ECE: 0.137, Precision: 0.679, Recall: 0.613\n","EPOCH -- 431\n","Iteration: 0. Train Loss: 1.06077. Val Loss: 0.95099, F1: 0.566, ECE: 0.138, Precision: 0.668, Recall: 0.600\n","EPOCH -- 432\n","Iteration: 0. Train Loss: 1.06195. Val Loss: 0.94814, F1: 0.566, ECE: 0.138, Precision: 0.668, Recall: 0.600\n","EPOCH -- 433\n","Iteration: 0. Train Loss: 1.05976. Val Loss: 0.93970, F1: 0.577, ECE: 0.120, Precision: 0.679, Recall: 0.613\n","EPOCH -- 434\n","Iteration: 0. Train Loss: 1.06248. Val Loss: 0.93291, F1: 0.578, ECE: 0.132, Precision: 0.680, Recall: 0.613\n","EPOCH -- 435\n","Iteration: 0. Train Loss: 1.06217. Val Loss: 0.92112, F1: 0.590, ECE: 0.138, Precision: 0.692, Recall: 0.627\n","EPOCH -- 436\n","Iteration: 0. Train Loss: 1.06094. Val Loss: 0.92480, F1: 0.590, ECE: 0.129, Precision: 0.692, Recall: 0.627\n","EPOCH -- 437\n","Iteration: 0. Train Loss: 1.06103. Val Loss: 0.92864, F1: 0.566, ECE: 0.136, Precision: 0.669, Recall: 0.600\n","EPOCH -- 438\n","Iteration: 0. Train Loss: 1.06199. Val Loss: 0.93331, F1: 0.565, ECE: 0.140, Precision: 0.668, Recall: 0.600\n","EPOCH -- 439\n","Iteration: 0. Train Loss: 1.06164. Val Loss: 0.95043, F1: 0.565, ECE: 0.141, Precision: 0.668, Recall: 0.600\n","EPOCH -- 440\n","Iteration: 0. Train Loss: 1.06025. Val Loss: 0.95524, F1: 0.565, ECE: 0.134, Precision: 0.668, Recall: 0.600\n","EPOCH -- 441\n","Iteration: 0. Train Loss: 1.06172. Val Loss: 0.94175, F1: 0.565, ECE: 0.152, Precision: 0.668, Recall: 0.600\n","EPOCH -- 442\n","Iteration: 0. Train Loss: 1.06518. Val Loss: 0.94524, F1: 0.565, ECE: 0.145, Precision: 0.668, Recall: 0.600\n","EPOCH -- 443\n","Iteration: 0. Train Loss: 1.06414. Val Loss: 0.93445, F1: 0.566, ECE: 0.166, Precision: 0.668, Recall: 0.600\n","EPOCH -- 444\n","Iteration: 0. Train Loss: 1.06201. Val Loss: 0.94139, F1: 0.555, ECE: 0.138, Precision: 0.659, Recall: 0.587\n","EPOCH -- 445\n","Iteration: 0. Train Loss: 1.06282. Val Loss: 0.94321, F1: 0.577, ECE: 0.112, Precision: 0.679, Recall: 0.613\n","EPOCH -- 446\n","Iteration: 0. Train Loss: 1.06136. Val Loss: 0.95144, F1: 0.567, ECE: 0.131, Precision: 0.670, Recall: 0.600\n","EPOCH -- 447\n","Iteration: 0. Train Loss: 1.06287. Val Loss: 0.96271, F1: 0.577, ECE: 0.121, Precision: 0.679, Recall: 0.613\n","EPOCH -- 448\n","Iteration: 0. Train Loss: 1.06152. Val Loss: 0.96403, F1: 0.577, ECE: 0.125, Precision: 0.678, Recall: 0.613\n","EPOCH -- 449\n","Iteration: 0. Train Loss: 1.06466. Val Loss: 0.96196, F1: 0.577, ECE: 0.124, Precision: 0.678, Recall: 0.613\n","EPOCH -- 450\n","Iteration: 0. Train Loss: 1.06519. Val Loss: 0.94338, F1: 0.577, ECE: 0.128, Precision: 0.678, Recall: 0.613\n","EPOCH -- 451\n","Iteration: 0. Train Loss: 1.06051. Val Loss: 0.94104, F1: 0.566, ECE: 0.160, Precision: 0.668, Recall: 0.600\n","EPOCH -- 452\n","Iteration: 0. Train Loss: 1.06318. Val Loss: 0.94185, F1: 0.578, ECE: 0.145, Precision: 0.680, Recall: 0.613\n","EPOCH -- 453\n","Iteration: 0. Train Loss: 1.06062. Val Loss: 0.94907, F1: 0.578, ECE: 0.126, Precision: 0.680, Recall: 0.613\n","EPOCH -- 454\n","Iteration: 0. Train Loss: 1.06323. Val Loss: 0.95867, F1: 0.578, ECE: 0.122, Precision: 0.680, Recall: 0.613\n","EPOCH -- 455\n","Iteration: 0. Train Loss: 1.06502. Val Loss: 0.97529, F1: 0.554, ECE: 0.153, Precision: 0.657, Recall: 0.587\n","EPOCH -- 456\n","Iteration: 0. Train Loss: 1.06168. Val Loss: 0.97353, F1: 0.565, ECE: 0.141, Precision: 0.668, Recall: 0.600\n","EPOCH -- 457\n","Iteration: 0. Train Loss: 1.06025. Val Loss: 0.96328, F1: 0.565, ECE: 0.138, Precision: 0.668, Recall: 0.600\n","EPOCH -- 458\n","Iteration: 0. Train Loss: 1.06046. Val Loss: 0.94672, F1: 0.577, ECE: 0.124, Precision: 0.679, Recall: 0.613\n","EPOCH -- 459\n","Iteration: 0. Train Loss: 1.06337. Val Loss: 0.93944, F1: 0.577, ECE: 0.155, Precision: 0.678, Recall: 0.613\n","EPOCH -- 460\n","Iteration: 0. Train Loss: 1.06216. Val Loss: 0.94303, F1: 0.577, ECE: 0.137, Precision: 0.679, Recall: 0.613\n","EPOCH -- 461\n","Iteration: 0. Train Loss: 1.06078. Val Loss: 0.95546, F1: 0.577, ECE: 0.138, Precision: 0.679, Recall: 0.613\n","EPOCH -- 462\n","Iteration: 0. Train Loss: 1.06124. Val Loss: 0.96452, F1: 0.577, ECE: 0.144, Precision: 0.679, Recall: 0.613\n","EPOCH -- 463\n","Iteration: 0. Train Loss: 1.06032. Val Loss: 0.96444, F1: 0.577, ECE: 0.130, Precision: 0.679, Recall: 0.613\n","EPOCH -- 464\n","Iteration: 0. Train Loss: 1.06210. Val Loss: 0.96549, F1: 0.578, ECE: 0.134, Precision: 0.680, Recall: 0.613\n","EPOCH -- 465\n","Iteration: 0. Train Loss: 1.06040. Val Loss: 0.96204, F1: 0.578, ECE: 0.128, Precision: 0.680, Recall: 0.613\n","EPOCH -- 466\n","Iteration: 0. Train Loss: 1.06251. Val Loss: 0.96246, F1: 0.577, ECE: 0.125, Precision: 0.679, Recall: 0.613\n","EPOCH -- 467\n","Iteration: 0. Train Loss: 1.06138. Val Loss: 0.95438, F1: 0.577, ECE: 0.141, Precision: 0.678, Recall: 0.613\n","EPOCH -- 468\n","Iteration: 0. Train Loss: 1.06186. Val Loss: 0.95808, F1: 0.577, ECE: 0.128, Precision: 0.678, Recall: 0.613\n","EPOCH -- 469\n","Iteration: 0. Train Loss: 1.06182. Val Loss: 0.95573, F1: 0.577, ECE: 0.138, Precision: 0.678, Recall: 0.613\n","EPOCH -- 470\n","Iteration: 0. Train Loss: 1.06236. Val Loss: 0.95865, F1: 0.577, ECE: 0.138, Precision: 0.679, Recall: 0.613\n","EPOCH -- 471\n","Iteration: 0. Train Loss: 1.05997. Val Loss: 0.96936, F1: 0.577, ECE: 0.129, Precision: 0.679, Recall: 0.613\n","EPOCH -- 472\n","Iteration: 0. Train Loss: 1.06043. Val Loss: 0.96318, F1: 0.577, ECE: 0.133, Precision: 0.679, Recall: 0.613\n","EPOCH -- 473\n","Iteration: 0. Train Loss: 1.06064. Val Loss: 0.96156, F1: 0.577, ECE: 0.132, Precision: 0.679, Recall: 0.613\n","EPOCH -- 474\n","Iteration: 0. Train Loss: 1.06016. Val Loss: 0.96118, F1: 0.577, ECE: 0.129, Precision: 0.679, Recall: 0.613\n","EPOCH -- 475\n","Iteration: 0. Train Loss: 1.06170. Val Loss: 0.96152, F1: 0.577, ECE: 0.131, Precision: 0.679, Recall: 0.613\n","EPOCH -- 476\n","Iteration: 0. Train Loss: 1.06083. Val Loss: 0.95927, F1: 0.577, ECE: 0.144, Precision: 0.679, Recall: 0.613\n","EPOCH -- 477\n","Iteration: 0. Train Loss: 1.06217. Val Loss: 0.96776, F1: 0.577, ECE: 0.130, Precision: 0.679, Recall: 0.613\n","EPOCH -- 478\n","Iteration: 0. Train Loss: 1.07131. Val Loss: 0.96355, F1: 0.577, ECE: 0.131, Precision: 0.679, Recall: 0.613\n","EPOCH -- 479\n","Iteration: 0. Train Loss: 1.06428. Val Loss: 0.96044, F1: 0.577, ECE: 0.132, Precision: 0.679, Recall: 0.613\n","EPOCH -- 480\n","Iteration: 0. Train Loss: 1.06112. Val Loss: 0.96126, F1: 0.577, ECE: 0.127, Precision: 0.679, Recall: 0.613\n","EPOCH -- 481\n","Iteration: 0. Train Loss: 1.06214. Val Loss: 0.96594, F1: 0.578, ECE: 0.125, Precision: 0.680, Recall: 0.613\n","EPOCH -- 482\n","Iteration: 0. Train Loss: 1.06621. Val Loss: 0.96545, F1: 0.578, ECE: 0.128, Precision: 0.680, Recall: 0.613\n","EPOCH -- 483\n","Iteration: 0. Train Loss: 1.06003. Val Loss: 0.97215, F1: 0.578, ECE: 0.132, Precision: 0.680, Recall: 0.613\n","EPOCH -- 484\n","Iteration: 0. Train Loss: 1.06267. Val Loss: 0.97179, F1: 0.578, ECE: 0.132, Precision: 0.680, Recall: 0.613\n","EPOCH -- 485\n","Iteration: 0. Train Loss: 1.06269. Val Loss: 0.97450, F1: 0.577, ECE: 0.134, Precision: 0.679, Recall: 0.613\n","EPOCH -- 486\n","Iteration: 0. Train Loss: 1.06078. Val Loss: 0.96998, F1: 0.577, ECE: 0.133, Precision: 0.679, Recall: 0.613\n","EPOCH -- 487\n","Iteration: 0. Train Loss: 1.06094. Val Loss: 0.96647, F1: 0.577, ECE: 0.137, Precision: 0.679, Recall: 0.613\n","EPOCH -- 488\n","Iteration: 0. Train Loss: 1.06253. Val Loss: 0.96561, F1: 0.578, ECE: 0.129, Precision: 0.680, Recall: 0.613\n","EPOCH -- 489\n","Iteration: 0. Train Loss: 1.06382. Val Loss: 0.95161, F1: 0.578, ECE: 0.128, Precision: 0.680, Recall: 0.613\n","EPOCH -- 490\n","Iteration: 0. Train Loss: 1.06241. Val Loss: 0.95182, F1: 0.577, ECE: 0.122, Precision: 0.678, Recall: 0.613\n","EPOCH -- 491\n","Iteration: 0. Train Loss: 1.06183. Val Loss: 0.96023, F1: 0.566, ECE: 0.169, Precision: 0.669, Recall: 0.600\n","EPOCH -- 492\n","Iteration: 0. Train Loss: 1.06027. Val Loss: 0.95269, F1: 0.567, ECE: 0.149, Precision: 0.672, Recall: 0.600\n","EPOCH -- 493\n","Iteration: 0. Train Loss: 1.06030. Val Loss: 0.97077, F1: 0.566, ECE: 0.134, Precision: 0.668, Recall: 0.600\n","EPOCH -- 494\n","Iteration: 0. Train Loss: 1.06083. Val Loss: 0.95445, F1: 0.578, ECE: 0.121, Precision: 0.721, Recall: 0.613\n","EPOCH -- 495\n","Iteration: 0. Train Loss: 1.06072. Val Loss: 0.96410, F1: 0.567, ECE: 0.145, Precision: 0.670, Recall: 0.600\n","EPOCH -- 496\n","Iteration: 0. Train Loss: 1.06404. Val Loss: 0.95038, F1: 0.577, ECE: 0.143, Precision: 0.679, Recall: 0.613\n","EPOCH -- 497\n","Iteration: 0. Train Loss: 1.06427. Val Loss: 0.95835, F1: 0.577, ECE: 0.122, Precision: 0.679, Recall: 0.613\n","EPOCH -- 498\n","Iteration: 0. Train Loss: 1.06421. Val Loss: 0.95828, F1: 0.565, ECE: 0.136, Precision: 0.668, Recall: 0.600\n","EPOCH -- 499\n","Iteration: 0. Train Loss: 1.06326. Val Loss: 0.95996, F1: 0.565, ECE: 0.132, Precision: 0.668, Recall: 0.600\n"],"name":"stdout"}]}]}